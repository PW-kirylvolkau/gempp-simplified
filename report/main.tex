\documentclass[11pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel} % albo [polish], jeśli raport ma być po polsku
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{geometry}
\usepackage{placeins}
\geometry{margin=2.5cm}

\title{Graph Distance and Minimal Extension\\
  \large Algorithms and Computability – Project Report}
\author{Borkowicz Dominik \and Volkau Kiryl \and Włodarczyk Wiktoria }
\date{\today}

\begin{document}

\maketitle

\section{Introduction}

Graphs are a standard model for discrete structures such as communication
networks, social networks or molecular structures. The project considers two
finite simple undirected graphs $G_1$ and $G_2$ given by adjacency matrices
and addresses three questions:
\begin{itemize}
  \item how to quantify the \emph{size} of a graph in a way that reflects
        algorithmic difficulty,
  \item how to define a \emph{distance} between graphs,
  \item how many vertices and edges must be added to $G_2$ so that it contains
        a prescribed number of subgraphs isomorphic to $G_1$.
\end{itemize}
The implementation is based on Integer Linear Programming (ILP) and the GLPK
solver and supports both exact and relaxed formulations of these problems.



\section{Preliminaries and Definitions}

We begin by specifying our graph model and by introducing the key concepts used throughout the report: graph size, a distance function on graphs, graph and subgraph isomorphism, and the minimal extension problem.

\subsection{Graph Model and Input Format}

In this project we work with finite simple undirected graphs.
A graph is a pair $G = (V,E)$, where $V$ is a finite set of vertices and $E$ is a set of unordered pairs $\{u,v\}$ with $u,v \in V$ and $u \neq v$.
Self-loops are not allowed.

We represent graphs by symmetric adjacency matrices with binary entries.
Let $G = (V,E)$ with $V = \{1,\dots,n\}$.
The adjacency matrix $A \in \{0,1\}^{n \times n}$ of $G$ is defined by
\[
  A_{ij} = \begin{cases} 1 & \text{if } \{i,j\} \in E, \\ 0 & \text{otherwise.} \end{cases}
\]
Since the graph is undirected, the matrix is symmetric ($A_{ij} = A_{ji}$); diagonal entries are zero because self-loops are disallowed.



\subsection{Size of a graph}

In standard graph theory the \emph{order} of a graph is the number of vertices
$|V(G)|$, and the \emph{edge size} is the number of edges $|E(G)|$. Here a
single scalar is used to reflect how large and complex an instance is from an
algorithmic point of view.

\textbf{Definition 2.1 (Graph size).}
For a finite simple graph $G$ the \emph{size} is
\[
\|G\| = |V(G)| + |E(G)|.
\]

\subsubsection*{Justification}

The definition has several useful properties:

\begin{enumerate}
  \item \textbf{Non-negativity and normalisation.} For any graph $G$,
        $|V(G)|,|E(G)| \ge 0$, hence $\|G\| \ge 0$ and $\|\emptyset\| = 0$.
  \item \textbf{Monotonicity under extensions.} If $G$ is a subgraph of $H$,
        then $|V(G)| \le |V(H)|$ and $|E(G)| \le |E(H)|$, so $\|G\| \le \|H\|$.
  \item \textbf{Additivity for disjoint unions.} If $G_1$ and $G_2$ are
        vertex-disjoint, then
        \[
          \|G_1 \cup G_2\| = \|G_1\| + \|G_2\|.
        \]
  \item \textbf{Relevance for computational complexity.} For sparse graphs
        $|E(G)|$ is of the same order as $|V(G)|$, while for dense graphs
        $|E(G)|$ can be quadratic in $|V(G)|$. The quantity
        $|V(G)| + |E(G)|$ is close to the size of the input and naturally
        appears in complexity bounds.
\end{enumerate}

\subsection{Distance between graphs: graph edit distance}

A metric on the set of all finite simple graphs should quantify how many local
changes are needed to transform one graph into another.

Let $\mathcal{G}$ denote the set of all finite simple graphs. A function
\[
d : \mathcal{G} \times \mathcal{G} \to \mathbb{R}_{\ge 0}
\]
is a \emph{metric} if for all $F,G,H \in \mathcal{G}$:
\begin{enumerate}
  \item $d(G,H) \ge 0$ (non-negativity),
  \item $d(G,H) = 0$ if and only if $G$ and $H$ are isomorphic,
  \item $d(G,H) = d(H,G)$,
  \item $d(F,H) \le d(F,G) + d(G,H)$.
\end{enumerate}

\subsubsection{Edit operations}

The following edit operations on graphs are considered:
\begin{enumerate}
  \item \emph{Vertex insertion}: add a new isolated vertex.
  \item \emph{Vertex deletion}: remove an existing vertex and all incident
        edges.
  \item \emph{Edge insertion}: add a new edge between two non-adjacent
        vertices.
  \item \emph{Edge deletion}: remove an existing edge.
\end{enumerate}

Each operation $e$ has a non-negative cost $c(e)$. In the basic setting
constant costs are used:
\begin{itemize}
  \item $c_v > 0$ for vertex insertion and deletion,
  \item $c_e > 0$ for edge insertion and deletion.
\end{itemize}

An \emph{edit path} from a graph $G$ to a graph $H$ is a finite sequence of
edit operations that transforms $G$ into a graph isomorphic to $H$. Its cost is
\[
C(P) = \sum_{i=1}^k c(e_i).
\]

\subsubsection{Definition of graph edit distance}

For two graphs $G$ and $H$ the \emph{graph edit distance} is
\[
d_{\mathrm{GED}}(G,H)
= \min\{ C(P) : P \text{ is an edit path from } G \text{ to } H \}.
\]

Under the above assumptions on the cost function, $d_{\mathrm{GED}}$ satisfies
the metric axioms:

\begin{itemize}
  \item \textbf{Non-negativity} follows from non-negative individual costs.
  \item \textbf{Identity of indiscernibles:} for isomorphic graphs an empty
        edit path has cost $0$, and if $d_{\mathrm{GED}}(G,H)=0$ then no edits
        are needed, so the graphs must be isomorphic.
  \item \textbf{Symmetry} holds because every edit operation has an inverse
        with the same cost.
  \item \textbf{Triangle inequality} holds because concatenating optimal edit
        paths from $F$ to $G$ and from $G$ to $H$ yields an edit path from $F$
        to $H$ whose cost is at least $d_{\mathrm{GED}}(F,H)$.
\end{itemize}

\subsection{Graph and Subgraph Isomorphism}

Two graphs $G = (V_G,E_G)$ and $H = (V_H,E_H)$ are \emph{isomorphic} if there exists a bijection
$f : V_G \to V_H$ such that
\[
  \{u,v\} \in E_G \quad \Longleftrightarrow \quad \{f(u), f(v)\} \in E_H
  \quad \text{for all } u,v \in V_G.
\]
Intuitively, isomorphic graphs have the same structure, differing only by the naming of vertices.

A graph $G$ is \emph{isomorphic to a subgraph} of $H$ if there exists an injective mapping
$f : V_G \to V_H$ such that
\[
  \{u,v\} \in E_G \quad \Longrightarrow \quad \{f(u), f(v)\} \in E_H
  \quad \text{for all } u,v \in V_G.
\]
In this case $H$ is said to \emph{contain} $G$ as a subgraph.
The subgraph isomorphism problem---deciding whether such an injective mapping exists---is a classical NP-complete problem.

There is a close connection between graph edit distance and (sub)graph isomorphism.
In particular, if the edit operations are restricted to vertex and edge relabellings and the cost of deletions and insertions is sufficiently large, then $\mathrm{GED}(G,H) = 0$ if and only if $G$ and $H$ are isomorphic.
Similarly, if only insertion operations are allowed, GED reduces to a measure of how far a graph is from containing another as a subgraph.

\subsection{Minimal Extension Problem}

We are now ready to formalize the main problem studied in this project.
Let $G$ and $H$ be two graphs.
We say that a graph $H'$ is an \emph{extension} of $H$ if $H$ is a subgraph of $H'$, that is, $V(H) \subseteq V(H')$ and $E(H) \subseteq E(H')$.

Given a pattern graph $G$, a base graph $H$, and an integer $k \geq 1$, the \emph{minimal extension problem} is defined as follows:
find an extension $H'$ of $H$ such that
\begin{itemize}
  \item $H'$ contains at least $k$ subgraphs that are isomorphic to $G$, and
  \item the number of vertices and edges added to $H$ to obtain $H'$ is minimal.
\end{itemize}
Equivalently, we seek an extension $H'$ minimizing the quantity
\[
  \Delta(H,H') = (|V(H')| - |V(H)|) + (|E(H')| - |E(H)|)
\]
subject to the constraint that $H'$ contains at least $k$ subgraphs isomorphic to $G$.

This problem can be viewed as a constrained variant of graph edit distance, where we allow only insertion operations and require the extended graph to contain a prescribed number of occurrences of a given pattern.

\section{Exact Algorithms}

In this section we describe exact algorithms for the problems introduced above.
We first discuss exact computation of the graph edit distance based on formulations proposed in the literature, and then we outline an exact approach to the minimal extension problem via exhaustive search of subgraph isomorphisms.
In both cases the algorithms have exponential worst-case complexity, which motivates the approximate methods presented in Section~\ref{sec:approx}.
 
\subsection{Exact Graph Edit Distance}
\label{subsec:exact-ged}

Exact computation of the graph edit distance is NP-hard in general and can be approached via binary linear programming (BLP).
In our implementation we follow the \emph{F2} formulation of Lerouge et al.\ \cite{lerougeBLP}, which is a reduced-size exact formulation compared to the straightforward model (\emph{F1}).

Let $G_1=(V_1,E_1)$ and $G_2=(V_2,E_2)$ be two graphs.
The formulation introduces two families of binary substitution variables:
\begin{itemize}
  \item $x_{i,k}\in\{0,1\}$ for $(i,k)\in V_1\times V_2$, where $x_{i,k}=1$ means that vertex $i$ is substituted (matched) with vertex $k$;
  \item $y_{e,f}\in\{0,1\}$ for $(e,f)\in E_1\times E_2$, where $y_{e,f}=1$ means that edge $e$ is substituted with edge $f$.
\end{itemize}
Deletion and insertion operations are handled implicitly: instead of explicit delete/insert variables, \emph{F2} uses a constant term corresponding to deleting and inserting all vertices and edges, and then subtracts the savings obtained by choosing substitutions.
Concretely, the objective has the form
\[
  \min_{x,y}\;\; C
  + \sum_{i\in V_1}\sum_{k\in V_2}\bigl(c_V(i\!\rightarrow\! k)-c_V(i\!\rightarrow\!\epsilon)-c_V(\epsilon\!\rightarrow\! k)\bigr)\,x_{i,k}
  + \sum_{e\in E_1}\sum_{f\in E_2}\bigl(c_E(e\!\rightarrow\! f)-c_E(e\!\rightarrow\!\epsilon)-c_E(\epsilon\!\rightarrow\! f)\bigr)\,y_{e,f},
\]
where $C = \sum_{i\in V_1}c_V(i\!\rightarrow\!\epsilon)+\sum_{k\in V_2}c_V(\epsilon\!\rightarrow\! k)+\sum_{e\in E_1}c_E(e\!\rightarrow\!\epsilon)+\sum_{f\in E_2}c_E(\epsilon\!\rightarrow\! f)$.
With unit insertion/deletion costs (our setting for unlabeled graphs), this simplifies to $C = |V_1|+|V_2|+|E_1|+|E_2|$.

The constraints enforce a one-to-one (partial) vertex assignment, a one-to-one edge assignment, and \emph{topological consistency} between the chosen vertex and edge substitutions.
The assignment constraints are:
\[
  \sum_{k\in V_2} x_{i,k} \le 1 \quad \forall i\in V_1,
  \qquad
  \sum_{i\in V_1} x_{i,k} \le 1 \quad \forall k\in V_2,
\]
and analogously for $y$ over $E_1$ and $E_2$.
The key reduction of \emph{F2} is to replace the quadratic number of edge-to-vertex compatibility constraints (one per pair of edges) by aggregated constraints indexed by vertices of $G_2$ (see \cite{lerougeBLP}).
For undirected graphs, this can be expressed as:
\[
  \sum_{f\in E_2:\; k\in f} y_{\{i,j\},f} \le x_{i,k}+x_{j,k}
  \qquad \forall \{i,j\}\in E_1,\; \forall k\in V_2.
\]

Solving this integer linear program yields an optimal edit path cost and therefore the exact value of $\mathrm{GED}(G_1,G_2)$.
The worst-case time complexity remains exponential (integer programming is NP-hard), but the reduced size of \emph{F2} makes it significantly more practical than the straightforward formulation for small and medium instances.

\subsection{Exact Subgraph Isomorphism and Minimal Extension}
\label{subsec:exact-extension}

We now turn to the minimal extension problem.
Recall that we are given a pattern graph $G$ and a base graph $H$, and we seek an extension $H'$ of $H$ that contains at least one subgraph isomorphic to $G$ while minimizing the number of added vertices and edges.

A conceptually simple exact algorithm is based on enumerating all injective mappings from the vertices of $G$ to the vertices of $H$ (and possibly to new vertices to be added) and computing, for each mapping, the minimal set of edges that must be added so that the image of $G$ under the mapping becomes a subgraph of the extended graph.

We first consider mappings into the existing vertices of $H$.
Let $V_G = \{1,\dots,n_G\}$ and $V_H = \{1,\dots,n_H\}$ with $n_G \leq n_H$.
An injective mapping $f : V_G \to V_H$ can be represented as an ordered $n_G$-tuple of distinct vertices of $H$.
For each such mapping we evaluate the \emph{deficit} of edges:
\[
  \mathrm{deficit}(f) = \left|\left\{ \{u,v\} \in E_G \;\middle|\; \{f(u), f(v)\} \notin E_H \right\}\right|.
\]
This quantity counts how many edges would need to be added to $H$ (between existing vertices) in order for the image of $G$ under $f$ to be realized as a subgraph of the extended graph.
The minimal deficit over all injective mappings into $V_H$ gives the minimal number of edge insertions required if we restrict ourselves to not adding new vertices.

If adding new vertices is allowed, the search space becomes even larger, since we may choose to map some vertices of $G$ to newly created vertices.
One possible exact strategy is then:
\begin{enumerate}
  \item For each integer $m \geq 0$ representing the number of new vertices to add, construct a hypothetical vertex set $V_H \cup V_{\mathrm{new}}$ with $|V_{\mathrm{new}}| = m$.
  \item Enumerate all injective mappings $f : V_G \to V_H \cup V_{\mathrm{new}}$.
  \item For each mapping compute the number of required edge insertions and count how many of them involve new vertices.
  \item Keep track of the mapping that minimizes the total number of inserted vertices and edges.
\end{enumerate}
The minimal total number of vertex and edge insertions over all considered values of $m$ gives the exact solution to the minimal extension problem.

The worst-case complexity of this exhaustive approach is clearly exponential.
Even if we restrict ourselves to mappings into the existing vertices of $H$, the number of injective mappings is
\[
  P(n_H, n_G) = \frac{n_H!}{(n_H - n_G)!},
\]
which grows superpolynomially in $n_H$ when $n_G$ is proportional to $n_H$.
For each mapping we must check all edges in $E_G$, which takes $O(|E_G|)$ time, or $O(n_G^2)$ in the worst case.
The overall worst-case time complexity is therefore
\[
  O\!\left(P(n_H, n_G) \cdot n_G^2\right),
\]
which is exponential in the size of the input graphs.

Because of this exponential behavior, exact algorithms for the minimal extension problem are practical only for very small graphs.
This observation motivates the design of approximate algorithms with polynomial-time complexity, as presented next.

\subsection{Minimal Extension via Minimum Cost Subgraph Matching (MCSM)}
\label{subsec:mcsm}

Our implementation computes the minimal extension using an integer linear programming (ILP) formulation of the \emph{Minimum Cost Subgraph Matching} (MCSM) problem \cite{lerougeMCSM}.
Conceptually, MCSM generalizes subgraph isomorphism by allowing a \emph{partial} injective mapping of the pattern into the target: some pattern vertices and edges may remain unmatched and incur a penalty.
With unit penalties for unmatched pattern elements, the MCSM objective directly corresponds to the ``minimal extension'' cost: the number of pattern vertices and edges that cannot be realized inside the target without adding new elements.

Let $G_1=(V_1,E_1)$ be the pattern and $G_2=(V_2,E_2)$ the target.
The formulation uses binary substitution variables
\(x_{i,k}\in\{0,1\}\) for $(i,k)\in V_1\times V_2$ and
\(y_{e,f}\in\{0,1\}\) for $(e,f)\in E_1\times E_2$,
where $x_{i,k}=1$ means that pattern vertex $i$ is matched to target vertex $k$ and $y_{e,f}=1$ means that pattern edge $e$ is matched to target edge $f$.
Deletions of pattern elements are handled implicitly: instead of explicit delete variables, the objective contains a constant term equal to the total ``creation cost'' of all pattern vertices and edges, and matching an element subtracts its creation cost and adds its substitution cost (which is $0$ in our unlabeled/unit-cost setting).
As a result, unmatched pattern vertices/edges contribute their full creation cost to the final objective.

The constraints enforce an injective partial mapping and topological consistency:
\begin{itemize}
  \item \textbf{Vertex injectivity.} Each pattern vertex is matched to at most one target vertex, and each target vertex is used by at most one pattern vertex:
  \[
    \sum_{k\in V_2} x_{i,k} \le 1 \quad \forall i\in V_1,
    \qquad
    \sum_{i\in V_1} x_{i,k} \le 1 \quad \forall k\in V_2.
  \]
  \item \textbf{Edge injectivity.} Each pattern edge is matched to at most one target edge (and symmetrically each target edge receives at most one pattern edge).
  \item \textbf{Edge--vertex consistency.} A pattern edge may be matched only to a target edge whose endpoints are compatible with the chosen endpoint matches.
  For undirected graphs, this can be enforced by aggregated constraints of the form
  \[
    \sum_{f\in E_2:\; k\in f} y_{e,f} \le x_{u,k}+x_{v,k}
    \quad \forall e=\{u,v\}\in E_1,\; \forall k\in V_2,
  \]
  which ensure that if $e$ is matched to an edge incident to $k$, then at least one endpoint of $e$ is matched to $k$.
\end{itemize}

This is exactly the approach implemented in our code in \texttt{src/formulation/mcsm.h}: the model allows \(\le 1\) (rather than equality) assignments for vertices and edges, and the objective counts the remaining unmatched pattern elements via their creation costs.
Optionally, we can also enforce an \emph{induced} subgraph match by adding constraints preventing the mapped target vertices from containing extra edges that are not matched by any pattern edge.


\section{Polynomial-Time Heuristic}
\label{sec:approx}

Exact algorithms for graph edit distance and the minimal extension problem are computationally expensive and do not scale to larger graphs.
In this section we describe a polynomial-time heuristic that provides an upper bound on the minimal extension without the exponential cost of exact methods.

\subsection{Greedy Heuristic for Minimal Extension}
\label{subsec:approx-extension}

To obtain a polynomial-time alternative to the exact ILP, we implement a greedy matching heuristic (see \texttt{src/solver/greedy\_solver.h}).
Note that this is a \emph{heuristic}, not a true approximation algorithm---it does not guarantee a bounded approximation ratio.
The algorithm directly constructs a feasible partial injective mapping of pattern vertices into target vertices, and then matches pattern edges accordingly.
The number of unmatched pattern elements provides an \emph{upper bound} on the minimal extension size.

Let the pattern graph be $G=(V_G,E_G)$ and the target graph be $H=(V_H,E_H)$.
We maintain a partial injective vertex matching $m_V:V_G \rightharpoonup V_H$ and a partial edge matching $m_E:E_G \rightharpoonup E_H$.
The procedure is:
\begin{enumerate}
  \item Sort pattern vertices in non-increasing degree order (high-degree vertices first).
  \item For each pattern vertex $i$ in that order, pick an unused target vertex $k$ that maximizes a greedy score.
        The score is computed as $1000 \times (\text{edge-compatible neighbors}) - |\deg(i) - \deg(k)|$,
        which prioritizes edge compatibility while using degree similarity as a tie-breaker.
  \item Once $m_V$ is fixed, iterate over pattern edges $(i,j)\in E_G$.
        If both endpoints are matched, i.e.\ $m_V(i)=k$ and $m_V(j)=\ell$, and the target contains the corresponding edge $(k,\ell)\in E_H$ (respecting directedness), match this pattern edge to that target edge as long as it is not already used.
\end{enumerate}

Finally, we report the greedy objective as the number of unmatched pattern elements:
\[
  \widehat{\Delta}_{\mathrm{greedy}}(G,H) \;=\;
  \bigl|\{i\in V_G : m_V(i)\ \text{undefined}\}\bigr|
  \;+\;
  \bigl|\{e\in E_G : m_E(e)\ \text{undefined}\}\bigr|.
\]
We interpret these unmatched pattern vertices and edges as elements that would need to be \emph{added to the target} so that an embedding of $G$ becomes possible under the constructed correspondence.
Because the mapping is produced greedily, $\widehat{\Delta}_{\mathrm{greedy}}(G,H)$ is heuristic and is not guaranteed to be minimal; however, it is typically obtained very quickly and serves as a practical upper bound.

\subsection{Complexity and Guarantees}
\label{subsec:approx-discussion}

The greedy heuristic runs in $O(|V|^2 + |E|^2)$ time, which is polynomial in the input size.
It does not guarantee a bounded approximation ratio; however, it satisfies the task requirement of providing a polynomial-time alternative to the exponential exact algorithm.
Empirical results show that it often produces values close to optimal on small instances \cite{riesen2009}.

\section{Experimental Evaluation}
\label{sec:experiments}

\subsection{Input Size Measures}
For an instance consisting of a pattern graph $G_1=(V_1,E_1)$ and a target graph $G_2=(V_2,E_2)$, we report:
\[
  |V_1|,\; |E_1|,\; |V_2|,\; |E_2|,
\]
as well as the graph size $\mathrm{size}(G)=|V|+|E|$ introduced earlier.
For the optimization-based methods, a useful proxy for difficulty is the number of decision variables, which is on the order of $|V_1||V_2|$ (vertex matches) plus $|E_1||E_2|$ (edge matches), with additional constraints enforcing injectivity and edge consistency.

\subsection{Experimental Setup}
All experiments were run using the provided command-line tool \texttt{gempp} built with the standard CMake build scripts.
We measure wall-clock runtime using the program's built-in \texttt{--time} flag, which reports elapsed time in milliseconds for a single run (including parsing, model construction, solving, and solution extraction).

\subsection{Synthetic Instances}
To make the evaluation reproducible, we generated a small set of synthetic instances and stored them in \texttt{report/experiments\_inputs/}.
Table~\ref{tab:exp-instances} lists their sizes.

\begin{table}[h]
\centering
\begin{tabular}{lrrrr}
\toprule
Instance & $|V_1|$ & $|E_1|$ & $|V_2|$ & $|E_2|$ \\
\midrule
\texttt{exp1\_k3\_in\_p4} & 3 & 3  & 4 & 3  \\
\texttt{exp2\_p5\_in\_p4} & 5 & 4  & 4 & 3  \\
\texttt{exp3\_k4\_in\_p6} & 4 & 6  & 6 & 5  \\
\texttt{exp4\_c5\_in\_k5} & 5 & 5  & 5 & 10 \\
\texttt{exp5\_k6\_in\_k7} & 6 & 15 & 7 & 21 \\
\bottomrule
\end{tabular}
\caption{Synthetic inputs used in the experimental evaluation.}
\label{tab:exp-instances}
\end{table}

\subsection{Runtime and Result Comparison}
We evaluated two modes:
(i) minimal extension via MCSM (default),
and (ii) exact GED via the integer F2 formulation (\texttt{--ged}).
Table~\ref{tab:exp-results} summarizes the observed values and runtimes.

\begin{table}[h]
\centering
\begin{tabular}{lrrrr}
\toprule
 & \multicolumn{2}{c}{MinExt (MCSM)} & \multicolumn{2}{c}{GED (F2)} \\
\cmidrule(lr){2-3}\cmidrule(lr){4-5}
Instance & value & ms & value & ms \\
\midrule
\texttt{exp1\_k3\_in\_p4} & 1 & 8  & 3 & 1 \\
\texttt{exp2\_p5\_in\_p4} & 2 & 1  & 2 & 1 \\
\texttt{exp3\_k4\_in\_p6} & 3 & 30 & 7 & 30 \\
\texttt{exp4\_c5\_in\_k5} & 0 & 1  & 5 & 1 \\
\texttt{exp5\_k6\_in\_k7} & 0 & 46 & 7 & 46 \\
\bottomrule
\end{tabular}
\caption{Measured runtimes (ms) and objective values for minimal extension (MCSM) and graph edit distance (GED).}
\label{tab:exp-results}
\end{table}

\subsection{Discussion}
The results highlight an important point:
\begin{itemize}
  \item \textbf{Minimal extension vs.\ GED.} Even when $G_1$ is a subgraph of $G_2$ (extension cost $0$), the full GED can be positive because GED is symmetric and also accounts for deleting extra vertices/edges present in $G_2$ (e.g.\ \texttt{exp4\_c5\_in\_k5}).
\end{itemize}

\subsection{Larger-Scale Experiments}
\label{subsec:planned-large}

To evaluate scalability and behavior on denser inputs, we added three larger synthetic instances that cover grid-like, dense-complete, and degree-mismatched cases. Table~\ref{tab:planned-large} lists their sizes and structures.

\begin{table}[h]
\centering
\begin{tabular}{lrrrrl}
\toprule
Instance & $|V_1|$ & $|E_1|$ & $|V_2|$ & $|E_2|$ & Structure \\
\midrule
\texttt{exp6\_grid4\_in\_grid5} & 16 & 24 & 25 & 40 & $4{\times}4$ grid in $5{\times}5$ grid \\
\texttt{exp7\_k8\_in\_k10}      &  8 & 28 & 10 & 45 & $K_8$ in $K_{10}$ (dense) \\
\texttt{exp8\_tree12\_in\_path15} & 12 & 11 & 15 & 14 & balanced tree in long path \\
\bottomrule
\end{tabular}
\caption{Planned larger synthetic inputs for scalability experiments.}
\label{tab:planned-large}
\end{table}
\paragraph{Description of the instances.}
\begin{itemize}
  \item \texttt{exp6\_grid4\_in\_grid5}: the pattern is an induced subgrid, so minimal extension should be $0$. GED should equal the insertion cost of the missing $9$ vertices and $16$ edges, giving a value around $25$.
  \item \texttt{exp7\_k8\_in\_k10}: also a clean subgraph, so minimal extension $0$. GED should be driven by adding $2$ vertices and $17$ edges, for an expected value near $19$.
  \item \texttt{exp8\_tree12\_in\_path15}: all vertices are available, but the path lacks branching. We expect $2$--$3$ pattern edges to remain unmatched in the minimal-extension ILP, so the reported extension should be in that range. GED should be slightly higher because deleting surplus path edges competes with re-routing.
\end{itemize}

\subsubsection{Outcomes of the experiments.}


\begin{table}[h]
  \centering
  \begin{tabular}{lrr}
  \toprule
  Instance & MinExt & GED \\
  \midrule
  \texttt{exp6\_grid4\_in\_grid5}    & 0  & 25 \\
  \texttt{exp7\_k8\_in\_k10}         & 0  & 19 \\
  \texttt{exp8\_tree12\_in\_path15}  & 2  & -- \\
  \bottomrule
  \end{tabular}
  \caption{Objective values for larger instances. Note: \texttt{exp8} GED was not computed due to impractical runtime (MinExt alone took ${\sim}5.6$ minutes).}
  \label{tab:exp-results-large}
  \end{table}
\FloatBarrier



\section{Implementation and Usage}
This section provides a short technical description of the implemented program and practical instructions for compiling and running it, as required by the laboratory task specification \cite{lerougeMCSM}.

\subsection{Software Architecture}
The project is a small C++17 command-line application that formulates the considered problems as linear/integer linear programs and solves them using GLPK.
The code is organized into a few focused modules:
\begin{itemize}
  \item \textbf{Input parsing} (\texttt{src/model/adjacency\_parser.h}): reads two graphs from a single text file containing adjacency matrices.
  \item \textbf{Graph model} (\texttt{src/model/graph.h}, \texttt{src/model/problem.h}): in-memory representation of the pattern and target graphs and the problem type (minimal extension vs.\ GED).
  \item \textbf{Formulations} (\texttt{src/formulation/}):
  \begin{itemize}
    \item \textbf{Minimal extension (default)}: a Minimum Cost Subgraph Matching (MCSM) ILP (\texttt{mcsm.h}), where the objective counts unmatched pattern vertices and edges.
    \item \textbf{Exact GED}: the F2 integer formulation implemented in \texttt{linear\_ged.h} (binary variables).
    \item \textbf{Greedy heuristic}: degree-based matching (\texttt{greedy\_solver.h}), which reports an upper bound on minimal extension (Section~\ref{subsec:approx-extension}).
  \end{itemize}
  \item \textbf{Solver backend} (\texttt{src/solver/glpk\_solver.h}): translates the internal LP/ILP representation to GLPK and extracts a solution.
  \item \textbf{CLI entry point} (\texttt{src/main.cpp}): parses command-line flags, runs the selected mode, and prints results.
\end{itemize}
GLPK (GNU Linear Programming Kit) is an open-source optimization library that can solve \emph{linear programs} (LP) and \emph{mixed-integer linear programs} (MILP) using implementations of simplex/interior-point methods and branch-and-bound/branch-and-cut techniques.
We use it as the underlying solver for our integer formulations (MCSM, F2).
For reproducibility, the repository also contains scripts for building, testing, and benchmarking (\texttt{scripts/}) and a small unit test suite (\texttt{tests/}).

\subsection{Running the Program}

\paragraph{Building.}
On Windows (laboratory environment), compile using:
\begin{verbatim}
scripts\build.bat
\end{verbatim}
On macOS/Linux:
\begin{verbatim}
./scripts/build.sh
\end{verbatim}
Alternatively, the build can be performed manually with CMake (e.g.\ \texttt{mkdir build \&\& cd build; cmake ..; make}).
The resulting executable is \texttt{gempp.exe} on Windows and \texttt{gempp} on macOS/Linux.

\paragraph{Input format.}
The program reads a \emph{single} text file containing two graphs (pattern first, target second):
\begin{verbatim}
<pattern_vertex_count>
<pattern_adjacency_matrix rows>

<target_vertex_count>
<target_adjacency_matrix rows>
\end{verbatim}
Entries are integers; for simple graphs they are $0/1$.
For undirected graphs the adjacency matrix should be symmetric and the diagonal typically contains zeros.

\paragraph{Basic usage.}
\begin{verbatim}
./gempp [--time] [--ged] [--fast] <input_file.txt>
\end{verbatim}
Important flags:
\begin{itemize}
  \item \texttt{(no flag)}: compute the minimal extension (pattern into target) using the MCSM ILP formulation.
  \item \texttt{--ged} (or \texttt{-g}): solve full GED using the exact F2 integer formulation.
  \item \texttt{--fast} (or \texttt{-f}): use the greedy heuristic for a fast approximation of the minimal extension (upper bound).
  \item \texttt{--time} (or \texttt{-t}): show computation time in milliseconds.
\end{itemize}

\paragraph{Output.}
In minimal-extension mode (default) the program prints:
\begin{verbatim}
GED: <value>
Is Subgraph: <yes|no>
Minimal Extension: <value>
Vertices to add: <count>
Edges to add: <count>
Unmatched vertices: <list or "none">
Unmatched edges: <list or "none">
\end{verbatim}
In \texttt{--fast} (greedy) mode, the output is prefixed with \texttt{Mode: greedy (upper bound)}.
In \texttt{--ged} mode the program reports ``Is Isomorphic'' instead of ``Is Subgraph'' and lists unmatched vertices and edges on both sides (pattern and target).

\paragraph{Testing.}
To verify correctness on the provided unit tests:
\begin{verbatim}
scripts\test.bat    (Windows)
./scripts/test.sh   (macOS/Linux)
\end{verbatim}
\textbf{Note on testing:} Due to the existence of multiple optimal solutions for some instances,
the test harness compares only the first five output lines (GED value, subgraph status,
minimal extension, vertex count, edge count) which are deterministic across platforms.

\section{Conclusions}

The work combines graph-theoretic concepts with an ILP-based implementation:

\begin{itemize}
  \item Graph size is defined as $\|G\| = |V(G)| + |E(G)|$, which aligns with
        the adjacency-matrix input size and is monotone under extensions.
  \item Graph edit distance $d_{\mathrm{GED}}$ is used as a metric on graphs
        and implemented via an ILP that counts vertex and edge insertions and
        deletions.
  \item Minimal extension is realised as a Minimum Cost Subgraph Matching
        problem, where the objective is the number of pattern vertices and
        edges that must be created in the target.
  \item The implementation is based on Integer Linear Programming (ILP) and the GLPK solver and supports both exact and relaxed formulations of these problems.
\end{itemize}

The experiments show two main regimes:

\begin{itemize}
  \item For graphs up to roughly 8--10 vertices (including dense complete
        graphs) the exact ILP solver is fast enough for interactive use.
  \item For dense graphs of size 12--15 the number of ILP variables and the
        solving time increase rapidly, reaching tens of seconds or minutes,
        which matches the theoretical hardness of subgraph isomorphism and
        GED.
\end{itemize}

\subsection*{Limitations}

The current solution has several clear limitations:

\begin{itemize}
  \item \textbf{Instance size.} The ILP formulation does not scale beyond
        small and medium graphs. For dense graphs with more than about
        15 vertices the solver becomes impractically slow.
  \item \textbf{Edit cost model.} All edit operations have unit cost. More
        refined cost models (e.g.\ different penalties for vertex vs.\ edge
        edits) are not exposed in the command-line interface.
  \item \textbf{Minimal extension parameter $k$.} The implementation focuses on
        $k=1$ (one copy of the pattern). Multiple required copies would need
        additional constraints in the ILP.
 
\end{itemize}



\section*{References}
\begin{thebibliography}{9}

\bibitem{riesen2009}
P.~Riesen and H.~Bunke,
\emph{Approximate graph edit distance computation by means of bipartite graph matching},
Image and Vision Computing, 2009.

\bibitem{lerougeBLP}
J.~Lerouge, Z.~Abu-Aisheh, R.~Raveaux, P.~H{\'e}roux, and S.~Adam,
\emph{Graph edit distance: A new binary linear programming formulation},
Pattern Recognition Letters, 2015.

\bibitem{lerougeMCSM}
J.~Lerouge, M.~Hammami, P.~H{\'e}roux, and S.~Adam,
\emph{Minimum cost subgraph matching using a binary linear program},
Pattern Recognition Letters, 2016.

\end{thebibliography}

\end{document}

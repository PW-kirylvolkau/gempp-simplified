\documentclass[11pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel} % albo [polish], jeśli raport ma być po polsku
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{geometry}
\usepackage{placeins}
\geometry{margin=2.5cm}

\title{Graph Distance and Minimal Extension\\
  \large Algorithms and Computability – Project Report}
\author{Borkowicz Dominik \and Volkau Kiryl \and Włodarczyk Wiktoria }
\date{\today}

\begin{document}

\maketitle

\section{Introduction}

Graphs are a standard model for discrete structures such as communication
networks, social networks or molecular structures. The project considers two
finite simple undirected graphs $G_1$ and $G_2$ given by adjacency matrices
and focuses on three questions:
\begin{itemize}
  \item how to quantify the \emph{size} of a graph in a way that reflects
        algorithmic difficulty,
  \item how to define a \emph{distance} between graphs,
  \item how many vertices and edges must be added to $G_2$ so that it contains
        a prescribed number of subgraphs isomorphic to $G_1$.
\end{itemize}
The implementation is based on Integer Linear Programming (ILP) and the GLPK
solver and supports both exact and relaxed formulations of these problems.



\section{Preliminaries and Definitions}

We begin by specifying our graph model and by introducing the key concepts used throughout the report: graph size, a distance function on graphs, graph and subgraph isomorphism, and the minimal extension problem.

\subsection{Graph Model and Input Format}

In this project we work with finite directed \emph{multigraphs}.
A graph is a pair $G = (V,E)$, where $V$ is a finite set of vertices and $E$ is a multiset of ordered pairs $(u,v)$ with $u,v \in V$ and $u \neq v$.
Parallel directed edges between the same ordered endpoints are allowed; we keep the usual restriction of no self-loops for simplicity.

We represent graphs by adjacency matrices with integer entries.
Let $G = (V,E)$ with $V = \{1,\dots,n\}$.
The adjacency matrix $A \in \mathbb{N}^{n \times n}$ of $G$ is defined by
\[
  A_{ij} = \#\bigl\{ e \in E \mid e = (i,j) \bigr\},
\]
so $A_{ij}$ stores the multiplicity of edges from $i$ to $j$.
The matrix need not be symmetric; diagonal entries are zero because self-loops are disallowed.



\subsection{Size of a graph}

In standard graph theory the \emph{order} of a graph is the number of vertices
$|V(G)|$, and the \emph{edge size} is the number of edges $|E(G)|$. Here a
single scalar is used to reflect how large and complex an instance is from an
algorithmic point of view.

\textbf{Definition 2.1 (Graph size).}
For a finite simple graph $G$ the \emph{size} is
\[
\|G\| = |V(G)| + |E(G)|.
\]

\subsubsection*{Justification}

The definition has several useful properties:

\begin{enumerate}
  \item \textbf{Non-negativity and normalisation.} For any graph $G$,
        $|V(G)|,|E(G)| \ge 0$, hence $\|G\| \ge 0$ and $\|\emptyset\| = 0$.
  \item \textbf{Monotonicity under extensions.} If $G$ is a subgraph of $H$,
        then $|V(G)| \le |V(H)|$ and $|E(G)| \le |E(H)|$, so $\|G\| \le \|H\|$.
  \item \textbf{Additivity for disjoint unions.} If $G_1$ and $G_2$ are
        vertex-disjoint, then
        \[
          \|G_1 \cup G_2\| = \|G_1\| + \|G_2\|.
        \]
  \item \textbf{Relevance for computational complexity.} For sparse graphs
        $|E(G)|$ is of the same order as $|V(G)|$, while for dense graphs
        $|E(G)|$ can be quadratic in $|V(G)|$. The quantity
        $|V(G)| + |E(G)|$ is close to the size of the input and naturally
        appears in complexity bounds.
\end{enumerate}

\subsection{Distance between graphs: graph edit distance}

A metric on the set of all finite simple graphs should quantify how many local
changes are needed to transform one graph into another.

Let $\mathcal{G}$ denote the set of all finite simple graphs. A function
\[
d : \mathcal{G} \times \mathcal{G} \to \mathbb{R}_{\ge 0}
\]
is a \emph{metric} if for all $F,G,H \in \mathcal{G}$:
\begin{enumerate}
  \item $d(G,H) \ge 0$ (non-negativity),
  \item $d(G,H) = 0$ if and only if $G$ and $H$ are isomorphic,
  \item $d(G,H) = d(H,G)$,
  \item $d(F,H) \le d(F,G) + d(G,H)$.
\end{enumerate}

\subsubsection{Edit operations}

The following edit operations on graphs are considered:
\begin{enumerate}
  \item \emph{Vertex insertion}: add a new isolated vertex.
  \item \emph{Vertex deletion}: remove an existing vertex and all incident
        edges.
  \item \emph{Edge insertion}: add a new edge between two non-adjacent
        vertices.
  \item \emph{Edge deletion}: remove an existing edge.
\end{enumerate}

Each operation $e$ has a non-negative cost $c(e)$. In the basic setting
constant costs are used:
\begin{itemize}
  \item $c_v > 0$ for vertex insertion and deletion,
  \item $c_e > 0$ for edge insertion and deletion.
\end{itemize}

An \emph{edit path} from a graph $G$ to a graph $H$ is a finite sequence of
edit operations that transforms $G$ into a graph isomorphic to $H$. Its cost is
\[
C(P) = \sum_{i=1}^k c(e_i).
\]

\subsubsection{Definition of graph edit distance}

For two graphs $G$ and $H$ the \emph{graph edit distance} is
\[
d_{\mathrm{GED}}(G,H)
= \min\{ C(P) : P \text{ is an edit path from } G \text{ to } H \}.
\]

Under the above assumptions on the cost function, $d_{\mathrm{GED}}$ satisfies
the metric axioms:

\begin{itemize}
  \item \textbf{Non-negativity} follows from non-negative individual costs.
  \item \textbf{Identity of indiscernibles:} for isomorphic graphs an empty
        edit path has cost $0$, and if $d_{\mathrm{GED}}(G,H)=0$ then no edits
        are needed, so the graphs must be isomorphic.
  \item \textbf{Symmetry} holds because every edit operation has an inverse
        with the same cost.
  \item \textbf{Triangle inequality} holds because concatenating optimal edit
        paths from $F$ to $G$ and from $G$ to $H$ yields an edit path from $F$
        to $H$ whose cost is at least $d_{\mathrm{GED}}(F,H)$.
\end{itemize}

\subsection{Graph and Subgraph Isomorphism}

Two graphs $G = (V_G,E_G)$ and $H = (V_H,E_H)$ are \emph{isomorphic} if there exists a bijection
$f : V_G \to V_H$ such that
\[
  \{u,v\} \in E_G \quad \Longleftrightarrow \quad \{f(u), f(v)\} \in E_H
  \quad \text{for all } u,v \in V_G.
\]
Intuitively, isomorphic graphs have the same structure, differing only by the naming of vertices.

A graph $G$ is \emph{isomorphic to a subgraph} of $H$ if there exists an injective mapping
$f : V_G \to V_H$ such that
\[
  \{u,v\} \in E_G \quad \Longrightarrow \quad \{f(u), f(v)\} \in E_H
  \quad \text{for all } u,v \in V_G.
\]
In this case $H$ is said to \emph{contain} $G$ as a subgraph.
The subgraph isomorphism problem---deciding whether such an injective mapping exists---is a classical NP-complete problem.

There is a close connection between graph edit distance and (sub)graph isomorphism.
In particular, if the edit operations are restricted to vertex and edge relabellings and the cost of deletions and insertions is sufficiently large, then $\mathrm{GED}(G,H) = 0$ if and only if $G$ and $H$ are isomorphic.
Similarly, if only insertion operations are allowed, GED reduces to a measure of how far a graph is from containing another as a subgraph.

\subsection{Minimal Extension Problem}

We are now ready to formalize the main problem studied in this project.
Let $G$ and $H$ be two graphs.
We say that a graph $H'$ is an \emph{extension} of $H$ if $H$ is a subgraph of $H'$, that is, $V(H) \subseteq V(H')$ and $E(H) \subseteq E(H')$.

Given a pattern graph $G$, a base graph $H$, and an integer $k \geq 1$, the \emph{minimal extension problem} is defined as follows:
find an extension $H'$ of $H$ such that
\begin{itemize}
  \item $H'$ contains at least $k$ subgraphs that are isomorphic to $G$, and
  \item the number of vertices and edges added to $H$ to obtain $H'$ is minimal.
\end{itemize}
Equivalently, we seek an extension $H'$ minimizing the quantity
\[
  \Delta(H,H') = (|V(H')| - |V(H)|) + (|E(H')| - |E(H)|)
\]
subject to the constraint that $H'$ contains at least $k$ subgraphs isomorphic to $G$.

This problem can be viewed as a constrained variant of graph edit distance, where we allow only insertion operations and require the extended graph to contain a prescribed number of occurrences of a given pattern.

\section{Exact Algorithms}

In this section we describe exact algorithms for the problems introduced above.
We first discuss exact computation of the graph edit distance based on formulations proposed in the literature, and then we outline an exact approach to the minimal extension problem via exhaustive search of subgraph isomorphisms.
In both cases the algorithms have exponential worst-case complexity, which motivates the approximate methods presented in Section~\ref{sec:approx}.
 
\subsection{Exact Graph Edit Distance}
\label{subsec:exact-ged}

Exact computation of the graph edit distance is NP-hard in general and can be approached via binary linear programming (BLP).
In our implementation we follow the \emph{F2} formulation of Lerouge et al.\ \cite{lerougeBLP}, which is a reduced-size exact formulation compared to the straightforward model (\emph{F1}).

Let $G_1=(V_1,E_1)$ and $G_2=(V_2,E_2)$ be two graphs.
The formulation introduces two families of binary substitution variables:
\begin{itemize}
  \item $x_{i,k}\in\{0,1\}$ for $(i,k)\in V_1\times V_2$, where $x_{i,k}=1$ means that vertex $i$ is substituted (matched) with vertex $k$;
  \item $y_{e,f}\in\{0,1\}$ for $(e,f)\in E_1\times E_2$, where $y_{e,f}=1$ means that edge $e$ is substituted with edge $f$.
\end{itemize}
Deletion and insertion operations are handled implicitly: instead of explicit delete/insert variables, \emph{F2} uses a constant term corresponding to deleting and inserting all vertices and edges, and then subtracts the savings obtained by choosing substitutions.
Concretely, the objective has the form
\[
  \min_{x,y}\;\; C
  + \sum_{i\in V_1}\sum_{k\in V_2}\bigl(c_V(i\!\rightarrow\! k)-c_V(i\!\rightarrow\!\epsilon)-c_V(\epsilon\!\rightarrow\! k)\bigr)\,x_{i,k}
  + \sum_{e\in E_1}\sum_{f\in E_2}\bigl(c_E(e\!\rightarrow\! f)-c_E(e\!\rightarrow\!\epsilon)-c_E(\epsilon\!\rightarrow\! f)\bigr)\,y_{e,f},
\]
where $C = \sum_{i\in V_1}c_V(i\!\rightarrow\!\epsilon)+\sum_{k\in V_2}c_V(\epsilon\!\rightarrow\! k)+\sum_{e\in E_1}c_E(e\!\rightarrow\!\epsilon)+\sum_{f\in E_2}c_E(\epsilon\!\rightarrow\! f)$.
With unit insertion/deletion costs (our setting for unlabeled graphs), this simplifies to $C = |V_1|+|V_2|+|E_1|+|E_2|$.

The constraints enforce a one-to-one (partial) vertex assignment, a one-to-one edge assignment, and \emph{topological consistency} between the chosen vertex and edge substitutions.
The assignment constraints are:
\[
  \sum_{k\in V_2} x_{i,k} \le 1 \quad \forall i\in V_1,
  \qquad
  \sum_{i\in V_1} x_{i,k} \le 1 \quad \forall k\in V_2,
\]
and analogously for $y$ over $E_1$ and $E_2$.
The key reduction of \emph{F2} is to replace the quadratic number of edge-to-vertex compatibility constraints (one per pair of edges) by aggregated constraints indexed by vertices of $G_2$ (see \cite{lerougeBLP}).
For undirected graphs, this can be expressed as:
\[
  \sum_{f\in E_2:\; k\in f} y_{\{i,j\},f} \le x_{i,k}+x_{j,k}
  \qquad \forall \{i,j\}\in E_1,\; \forall k\in V_2.
\]

Solving this integer linear program yields an optimal edit path cost and therefore the exact value of $\mathrm{GED}(G_1,G_2)$.
The worst-case time complexity remains exponential (integer programming is NP-hard), but the reduced size of \emph{F2} makes it significantly more practical than the straightforward formulation for small and medium instances.

\subsection{Exact Subgraph Isomorphism and Minimal Extension}
\label{subsec:exact-extension}

We now turn to the minimal extension problem.
Recall that we are given a pattern graph $G$ and a base graph $H$, and we seek an extension $H'$ of $H$ that contains at least one subgraph isomorphic to $G$ while minimizing the number of added vertices and edges.

A conceptually simple exact algorithm is based on enumerating all injective mappings from the vertices of $G$ to the vertices of $H$ (and possibly to new vertices to be added) and computing, for each mapping, the minimal set of edges that must be added so that the image of $G$ under the mapping becomes a subgraph of the extended graph.

We first consider mappings into the existing vertices of $H$.
Let $V_G = \{1,\dots,n_G\}$ and $V_H = \{1,\dots,n_H\}$ with $n_G \leq n_H$.
An injective mapping $f : V_G \to V_H$ can be represented as an ordered $n_G$-tuple of distinct vertices of $H$.
For each such mapping we evaluate the \emph{deficit} of edges:
\[
  \mathrm{deficit}(f) = \left|\left\{ \{u,v\} \in E_G \;\middle|\; \{f(u), f(v)\} \notin E_H \right\}\right|.
\]
This quantity counts how many edges would need to be added to $H$ (between existing vertices) in order for the image of $G$ under $f$ to be realized as a subgraph of the extended graph.
The minimal deficit over all injective mappings into $V_H$ gives the minimal number of edge insertions required if we restrict ourselves to not adding new vertices.

If adding new vertices is allowed, the search space becomes even larger, since we may choose to map some vertices of $G$ to newly created vertices.
One possible exact strategy is then:
\begin{enumerate}
  \item For each integer $m \geq 0$ representing the number of new vertices to add, construct a hypothetical vertex set $V_H \cup V_{\mathrm{new}}$ with $|V_{\mathrm{new}}| = m$.
  \item Enumerate all injective mappings $f : V_G \to V_H \cup V_{\mathrm{new}}$.
  \item For each mapping compute the number of required edge insertions and count how many of them involve new vertices.
  \item Keep track of the mapping that minimizes the total number of inserted vertices and edges.
\end{enumerate}
The minimal total number of vertex and edge insertions over all considered values of $m$ gives the exact solution to the minimal extension problem.

The worst-case complexity of this exhaustive approach is clearly exponential.
Even if we restrict ourselves to mappings into the existing vertices of $H$, the number of injective mappings is
\[
  P(n_H, n_G) = \frac{n_H!}{(n_H - n_G)!},
\]
which grows superpolynomially in $n_H$ when $n_G$ is proportional to $n_H$.
For each mapping we must check all edges in $E_G$, which takes $O(|E_G|)$ time, or $O(n_G^2)$ in the worst case.
The overall worst-case time complexity is therefore
\[
  O\!\left(P(n_H, n_G) \cdot n_G^2\right),
\]
which is exponential in the size of the input graphs.

Because of this exponential behavior, exact algorithms for the minimal extension problem are practical only for very small graphs.
This observation motivates the design of approximate algorithms with polynomial-time complexity, as presented next.

\subsection{Minimal Extension via Minimum Cost Subgraph Matching (MCSM)}
\label{subsec:mcsm}

Our implementation computes the minimal extension using an integer linear programming (ILP) formulation of the \emph{Minimum Cost Subgraph Matching} (MCSM) problem \cite{lerougeMCSM}.
Conceptually, MCSM generalizes subgraph isomorphism by allowing a \emph{partial} injective mapping of the pattern into the target: some pattern vertices and edges may remain unmatched and incur a penalty.
With unit penalties for unmatched pattern elements, the MCSM objective directly corresponds to the ``minimal extension'' cost: the number of pattern vertices and edges that cannot be realized inside the target without adding new elements.

Let $G_1=(V_1,E_1)$ be the pattern and $G_2=(V_2,E_2)$ the target.
The formulation uses binary substitution variables
\(x_{i,k}\in\{0,1\}\) for $(i,k)\in V_1\times V_2$ and
\(y_{e,f}\in\{0,1\}\) for $(e,f)\in E_1\times E_2$,
where $x_{i,k}=1$ means that pattern vertex $i$ is matched to target vertex $k$ and $y_{e,f}=1$ means that pattern edge $e$ is matched to target edge $f$.
Deletions of pattern elements are handled implicitly: instead of explicit delete variables, the objective contains a constant term equal to the total ``creation cost'' of all pattern vertices and edges, and matching an element subtracts its creation cost and adds its substitution cost (which is $0$ in our unlabeled/unit-cost setting).
As a result, unmatched pattern vertices/edges contribute their full creation cost to the final objective.

The constraints enforce an injective partial mapping and topological consistency:
\begin{itemize}
  \item \textbf{Vertex injectivity.} Each pattern vertex is matched to at most one target vertex, and each target vertex is used by at most one pattern vertex:
  \[
    \sum_{k\in V_2} x_{i,k} \le 1 \quad \forall i\in V_1,
    \qquad
    \sum_{i\in V_1} x_{i,k} \le 1 \quad \forall k\in V_2.
  \]
  \item \textbf{Edge injectivity.} Each pattern edge is matched to at most one target edge (and symmetrically each target edge receives at most one pattern edge).
  \item \textbf{Edge--vertex consistency.} A pattern edge may be matched only to a target edge whose endpoints are compatible with the chosen endpoint matches.
  For undirected graphs, this can be enforced by aggregated constraints of the form
  \[
    \sum_{f\in E_2:\; k\in f} y_{e,f} \le x_{u,k}+x_{v,k}
    \quad \forall e=\{u,v\}\in E_1,\; \forall k\in V_2,
  \]
  which ensure that if $e$ is matched to an edge incident to $k$, then at least one endpoint of $e$ is matched to $k$.
\end{itemize}

This is exactly the approach implemented in our code in \texttt{src/formulation/mcsm.h}: the model allows \(\le 1\) (rather than equality) assignments for vertices and edges, and the objective counts the remaining unmatched pattern elements via their creation costs.
Optionally, we can also enforce an \emph{induced} subgraph match by adding constraints preventing the mapped target vertices from containing extra edges that are not matched by any pattern edge.


\section{Approximation Algorithms}
\label{sec:approx}

Exact algorithms for graph edit distance and the minimal extension problem are computationally expensive and do not scale to larger graphs.
In this section we describe approximation ideas that replace the exponential search space of exact formulations by tractable optimization problems.
In particular, for GED we use a linear programming relaxation (F2LP) of a binary linear formulation from the literature, which yields a polynomial-time computable lower bound.

\subsection{Approximate GED via LP Relaxation (F2LP)}
\label{subsec:approx-ged}

Instead of approximating GED via bipartite matching, we use the continuous relaxation of the binary linear programming formulation \emph{F2} proposed by Lerouge et al.\ \cite{lerougeBLP}.
In that work, \emph{F2LP} denotes the linear program obtained from \emph{F2} by relaxing all binary constraints to continuous bounds in $[0,1]$.
Solving \emph{F2LP} yields a polynomial-time computable \emph{lower bound} on the exact GED, and we use this value as our approximation.

Let $G_1=(V_1,E_1)$ and $G_2=(V_2,E_2)$ be two (simple, undirected) graphs.
We introduce decision variables:
\begin{itemize}
  \item $x_{i,k} \in [0,1]$ for each $(i,k)\in V_1\times V_2$, indicating to what extent vertex $i$ of $G_1$ is matched to vertex $k$ of $G_2$,
  \item $y_{e,f} \in [0,1]$ for each $(e,f)\in E_1\times E_2$, indicating to what extent edge $e$ of $G_1$ is matched to edge $f$ of $G_2$.
\end{itemize}

The \emph{F2} objective can be written as a constant corresponding to ``delete and insert everything'', plus correction terms for chosen substitutions:
\[
  \min_{x,y}\;\; C
  + \sum_{i\in V_1}\sum_{k\in V_2}\bigl(c_V(i\!\rightarrow\! k)-c_V(i\!\rightarrow\!\epsilon)-c_V(\epsilon\!\rightarrow\! k)\bigr)\,x_{i,k}
  + \sum_{e\in E_1}\sum_{f\in E_2}\bigl(c_E(e\!\rightarrow\! f)-c_E(e\!\rightarrow\!\epsilon)-c_E(\epsilon\!\rightarrow\! f)\bigr)\,y_{e,f}.
\]
In our experiments we use unit insertion/deletion costs and zero substitution costs for unlabeled graphs, so $C = |V_1|+|V_2|+|E_1|+|E_2|$, and matching vertices/edges decreases the objective accordingly.

The constraints enforce that $x$ behaves like a partial one-to-one assignment, and that $y$ is consistent with $x$:
\begin{align*}
  \sum_{k\in V_2} x_{i,k} &\le 1 && \forall i\in V_1,\\
  \sum_{i\in V_1} x_{i,k} &\le 1 && \forall k\in V_2,\\
  \sum_{f\in E_2} y_{e,f} &\le 1 && \forall e\in E_1,\\
  \sum_{e\in E_1} y_{e,f} &\le 1 && \forall f\in E_2,\\
  \sum_{f\in E_2:\; k\in f} y_{\{i,j\},f} &\le x_{i,k} + x_{j,k} && \forall \{i,j\}\in E_1,\;\forall k\in V_2,\\
  0 \le x_{i,k} \le 1,\;\; 0 \le y_{e,f} \le 1. &&
\end{align*}

The last family of constraints is the (undirected) \emph{edge consistency} condition: an edge $\{i,j\}\in E_1$ may be matched to an edge incident to $k\in V_2$ only if (at least) one of its endpoints is matched to $k$.
Replacing integrality ($\{0,1\}$) by bounds ($[0,1]$) gives the LP relaxation \emph{F2LP}, which can be solved efficiently by standard LP solvers.
The optimum value of \emph{F2LP} is a lower bound on the exact GED \cite{lerougeBLP}, and we report it as our polynomial-time approximation.

\subsection{Approximate Minimal Extension}
\label{subsec:approx-extension}

We also implemented a lightweight approximation of the minimal extension problem based on the same linear relaxation used for approximate GED, but with \emph{asymmetric} edit costs.
The key idea is to discourage deletions of pattern elements so that the optimization behaves like an ``embed the pattern into the target'' procedure.

Given a pattern graph $G=(V_G,E_G)$ and a base graph $H=(V_H,E_H)$, we solve the \emph{F2LP} relaxation (Section~\ref{subsec:approx-ged}) with costs chosen as:
\begin{itemize}
  \item insertion costs $c(\epsilon\rightarrow v)=1$ and $c(\epsilon\rightarrow e)=1$,
  \item deletion costs $c(v\rightarrow \epsilon)=M$ and $c(e\rightarrow \epsilon)=M$, where $M\gg 1$ is a very large constant.
\end{itemize}
Intuitively, with $M$ large the solver is strongly incentivized to \emph{avoid deleting} vertices and edges of $G$ and instead to explain discrepancies through the (cheaper) insertion of missing elements.
In our implementation we use $M=10^6$.

After solving the LP, we extract a discrete matching by treating variables with value at least $0.5$ as active.
Let $U_V$ be the set of pattern vertices not matched by any active $x_{i,k}$, and let $U_E$ be the set of pattern edges not matched by any active $y_{e,f}$.
We interpret these unmatched pattern elements as elements that would need to be \emph{added to $H$} so that an embedding of $G$ becomes possible, and we define the approximate extension size by
\[
  \widehat{\Delta}_{\mathrm{F2LP}}(H,H') = |U_V| + |U_E|.
\]
This procedure is heuristic: because we solve the relaxed program (continuous variables), the extracted matching may be fractional before thresholding, and the resulting count is only an approximation.

The overall running time is polynomial: solving the linear program dominates, and the post-processing step (counting unmatched pattern vertices and edges) is linear in $|V_G|+|E_G|$ once the active variables are identified.

\subsection{Discussion of Approximation Quality}
\label{subsec:approx-discussion}

The matching-based approach described above does not guarantee that the obtained value $\widehat{\mathrm{GED}}(G,H)$ equals the true graph edit distance, nor that the estimated extension cost $\widehat{\Delta}(H,H')$ is minimal.
The main source of approximation error is the locality of the cost matrix construction: the matching cost of two vertices is computed based on local information (labels, degrees, neighborhoods), whereas the global structure of the graphs may require more complex transformations.

Nevertheless, several practical advantages justify this approach:
\begin{itemize}
  \item The algorithm has polynomial worst-case complexity and can therefore handle graphs of significantly larger size than exact methods.
  \item The assignment-based correspondence typically captures a reasonable structural alignment between the graphs, especially when their local neighborhoods are informative.
  \item On small instances where the exact GED or exact minimal extension can be computed, empirical studies often show that the approximation is close to the true value \cite{riesen2009,lerougeBLP}.
\end{itemize}

In our experimental evaluation (Section~\ref{sec:experiments}) we compare the runtime and, where possible, the accuracy of the approximate methods against exact reference values.
The results confirm the expected trade-off: exact algorithms yield ground-truth distances but become infeasible beyond small graph sizes, while the approximate algorithms scale to larger inputs at the price of a moderate approximation error.

\section{Experimental Evaluation}
\label{sec:experiments}

\subsection{Input Size Measures}
For an instance consisting of a pattern graph $G_1=(V_1,E_1)$ and a target graph $G_2=(V_2,E_2)$, we report:
\[
  |V_1|,\; |E_1|,\; |V_2|,\; |E_2|,
\]
as well as the graph size $\mathrm{size}(G)=|V|+|E|$ introduced earlier.
For the optimization-based methods, a useful proxy for difficulty is the number of decision variables, which is on the order of $|V_1||V_2|$ (vertex matches) plus $|E_1||E_2|$ (edge matches), with additional constraints enforcing injectivity and edge consistency.

\subsection{Experimental Setup}
All experiments were run using the provided command-line tool \texttt{gempp} built with the standard CMake build scripts.
We measure wall-clock runtime using the program's built-in \texttt{--time} flag, which reports elapsed time in milliseconds for a single run (including parsing, model construction, solving, and solution extraction).

\subsection{Synthetic Instances}
To make the evaluation reproducible, we generated a small set of synthetic instances and stored them in \texttt{report/experiments\_inputs/}.
Table~\ref{tab:exp-instances} lists their sizes.

\begin{table}[h]
\centering
\begin{tabular}{lrrrr}
\toprule
Instance & $|V_1|$ & $|E_1|$ & $|V_2|$ & $|E_2|$ \\
\midrule
\texttt{exp1\_k3\_in\_p4} & 3 & 3  & 4 & 3  \\
\texttt{exp2\_p5\_in\_p4} & 5 & 4  & 4 & 3  \\
\texttt{exp3\_k4\_in\_p6} & 4 & 6  & 6 & 5  \\
\texttt{exp4\_c5\_in\_k5} & 5 & 5  & 5 & 10 \\
\texttt{exp5\_k6\_in\_k7} & 6 & 15 & 7 & 21 \\
\bottomrule
\end{tabular}
\caption{Synthetic inputs used in the experimental evaluation.}
\label{tab:exp-instances}
\end{table}

\subsection{Runtime and Result Comparison}
We evaluated four modes:
(i) minimal extension via MCSM (default),
(ii) exact GED via the integer F2 formulation (\texttt{--ged}),
(iii) the LP relaxation F2LP (\texttt{--f2lp}) yielding a lower bound on GED,
and (iv) the heuristic \texttt{--minext-approx} mode (F2LP with a very high deletion cost).
Table~\ref{tab:exp-results} summarizes the observed values and runtimes.

\begin{table}[h]
\centering
\begin{tabular}{lrrrrrrrr}
\toprule
 & \multicolumn{2}{c}{MinExt (MCSM)} & \multicolumn{2}{c}{GED (F2)} & \multicolumn{2}{c}{F2LP (LB)} & \multicolumn{2}{c}{MinExt-approx} \\
\cmidrule(lr){2-3}\cmidrule(lr){4-5}\cmidrule(lr){6-7}\cmidrule(lr){8-9}
Instance & value & ms & value & ms & value & ms & count & ms \\
\midrule
\texttt{exp1\_k3\_in\_p4} & 1 & 8  & 3 & 1  & 1.0 & 0 & 0  & 0 \\
\texttt{exp2\_p5\_in\_p4} & 2 & 1  & 2 & 1  & 2.0 & 0 & 4  & 0 \\
\texttt{exp3\_k4\_in\_p6} & 3 & 30 & 7 & 30 & 3.0 & 1 & 4  & 1 \\
\texttt{exp4\_c5\_in\_k5} & 0 & 1  & 5 & 1  & 5.0 & 1 & 0  & 0 \\
\texttt{exp5\_k6\_in\_k7} & 0 & 46 & 7 & 46 & 7.0 & 6 & 18 & 6 \\
\bottomrule
\end{tabular}
\caption{Measured runtimes (ms) and objective values for different modes. For \texttt{--f2lp}, the value is a lower bound on GED. For \texttt{--minext-approx}, ``count'' is the reported number of unmatched pattern vertices and edges after thresholding LP variables at $0.5$.}
\label{tab:exp-results}
\end{table}

\subsection{Discussion}
The results highlight several important points:
\begin{itemize}
  \item \textbf{Minimal extension vs.\ GED.} Even when $G_1$ is a subgraph of $G_2$ (extension cost $0$), the full GED can be positive because GED is symmetric and also accounts for deleting extra vertices/edges present in $G_2$ (e.g.\ \texttt{exp4\_c5\_in\_k5}).
  \item \textbf{Speed of F2LP.} The LP relaxation is consistently faster than solving the integer program on denser instances (e.g.\ \texttt{exp5\_k6\_in\_k7}: $6$ms vs.\ $46$ms), while providing a certified lower bound on GED.
  \item \textbf{Quality of the lower bound.} The bound can be tight on some instances (e.g.\ \texttt{exp4}, \texttt{exp5}) but loose on others (\texttt{exp1}, \texttt{exp3}), reflecting the relaxation gap.
  \item \textbf{Limitations of \texttt{--minext-approx}.} The high-deletion-penalty F2LP heuristic does not reliably recover the true minimal extension from the pattern-side unmatched count (e.g.\ \texttt{exp1} and \texttt{exp5}).
  This is expected because (a) the underlying optimization is a relaxation with fractional solutions, and (b) extracting a discrete matching by thresholding is itself heuristic.
\end{itemize}

\subsection{Larger-Scale Experiments}
\label{subsec:planned-large}

To evaluate scalability and behavior on denser inputs, we added three larger synthetic instances that cover grid-like, dense-complete, and degree-mismatched cases. Table~\ref{tab:planned-large} lists their sizes and structures.

\begin{table}[h]
\centering
\begin{tabular}{lrrrrl}
\toprule
Instance & $|V_1|$ & $|E_1|$ & $|V_2|$ & $|E_2|$ & Structure \\
\midrule
\texttt{exp6\_grid4\_in\_grid5} & 16 & 24 & 25 & 40 & $4{\times}4$ grid in $5{\times}5$ grid \\
\texttt{exp7\_k8\_in\_k10}      &  8 & 28 & 10 & 45 & $K_8$ in $K_{10}$ (dense) \\
\texttt{exp8\_tree12\_in\_path15} & 12 & 11 & 15 & 14 & balanced tree in long path \\
\bottomrule
\end{tabular}
\caption{Planned larger synthetic inputs for scalability experiments.}
\label{tab:planned-large}
\end{table}
\paragraph{Description of the instances.}
\begin{itemize}
  \item \texttt{exp6\_grid4\_in\_grid5}: the pattern is an induced subgrid, so minimal extension should be $0$. GED should equal the insertion cost of the missing $9$ vertices and $16$ edges, giving a value around $25$; \texttt{--f2lp} should match this because the mapping is tight.
  \item \texttt{exp7\_k8\_in\_k10}: also a clean subgraph, so minimal extension $0$. GED should be driven by adding $2$ vertices and $17$ edges, for an expected value near $19$; LP and ILP should coincide. 
  \item \texttt{exp8\_tree12\_in\_path15}: all vertices are available, but the path lacks branching. We expect $2$--$3$ pattern edges to remain unmatched in the minimal-extension ILP, so the reported extension should be in that range. GED should be slightly higher because deleting surplus path edges competes with re-routing.
\end{itemize}

\subsubsection{Outcomes of the experiments.}


\begin{table}[h]
  \centering
  \begin{tabular}{lrrrrrr}
  \toprule
   & \multicolumn{1}{c}{True MinExtension} & \multicolumn{1}{c}{True GED} & \multicolumn{2}{c}{F2LP (LB)} & \multicolumn{2}{c}{MinExt-approx} \\
  \cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(lr){4-5}\cmidrule(lr){6-7}
  Instance & value & value & value & ms & count & ms \\
  \midrule
  \texttt{exp6\_grid4\_in\_grid5}    & -- & -- & -- & -- & -- & -- \\
  \texttt{exp7\_k8\_in\_k10}         & -- & -- & -- & -- & -- & -- \\
  \texttt{exp8\_tree12\_in\_path15}  & -- & -- & -- & -- & -- & -- \\
  \bottomrule
  \end{tabular}
  \caption{Measured runtimes (ms) and objective values for different modes. For \texttt{--f2lp}, the value is a lower bound on GED. For \texttt{--minext-approx}, ``count'' is the reported number of unmatched pattern vertices and edges after thresholding LP variables at $0.5$.}
  \label{tab:exp-results}
  \end{table}
\FloatBarrier



\section{Implementation and Usage}
This section provides a short technical description of the implemented program and practical instructions for compiling and running it, as required by the laboratory task specification \cite{lerougeMCSM}.

\subsection{Software Architecture}
The project is a small C++17 command-line application that formulates the considered problems as linear/integer linear programs and solves them using GLPK.
The code is organized into a few focused modules:
\begin{itemize}
  \item \textbf{Input parsing} (\texttt{src/model/adjacency\_parser.h}): reads two graphs from a single text file containing adjacency matrices.
  \item \textbf{Graph model} (\texttt{src/model/graph.h}, \texttt{src/model/problem.h}): in-memory representation of the pattern and target graphs and the problem type (minimal extension vs.\ GED).
  \item \textbf{Formulations} (\texttt{src/formulation/}):
  \begin{itemize}
    \item \textbf{Minimal extension (default)}: a Minimum Cost Subgraph Matching (MCSM) ILP (\texttt{mcsm.h}), where the objective counts unmatched pattern vertices and edges.
    \item \textbf{Exact GED}: the F2 integer formulation implemented in \texttt{linear\_ged.h} (binary variables).
    \item \textbf{Approximate GED / bounds}: the F2LP relaxation in \texttt{linear\_ged.h} (continuous variables in $[0,1]$), enabled via a command-line flag.
    \item \textbf{Approximate minimal extension (heuristic)}: F2LP with a very high deletion penalty to discourage deleting pattern elements (Section~\ref{subsec:approx-extension}).
  \end{itemize}
  \item \textbf{Solver backend} (\texttt{src/solver/glpk\_solver.h}): translates the internal LP/ILP representation to GLPK and extracts a solution.
  \item \textbf{CLI entry point} (\texttt{src/main.cpp}): parses command-line flags, runs the selected mode, prints results, and optionally writes a GEM++-style XML solution file.
\end{itemize}
GLPK (GNU Linear Programming Kit) is an open-source optimization library that can solve \emph{linear programs} (LP) and \emph{mixed-integer linear programs} (MILP) using implementations of simplex/interior-point methods and branch-and-bound/branch-and-cut techniques.
We use it as the underlying solver for both our LP relaxation (F2LP) and our integer formulations (MCSM, F2).
For reproducibility, the repository also contains scripts for building, testing, and benchmarking (\texttt{scripts/}) and a small unit test suite (\texttt{tests/}).

\subsection{Running the Program}

\paragraph{Building.}
On Windows (laboratory environment), compile using:
\begin{verbatim}
scripts\build.bat
\end{verbatim}
On macOS/Linux:
\begin{verbatim}
./scripts/build.sh
\end{verbatim}
Alternatively, the build can be performed manually with CMake (e.g.\ \texttt{mkdir build \&\& cd build; cmake ..; make}).
The resulting executable is \texttt{gempp.exe} on Windows and \texttt{gempp} on macOS/Linux.

\paragraph{Input format.}
The program reads a \emph{single} text file containing two graphs (pattern first, target second):
\begin{verbatim}
<pattern_vertex_count>
<pattern_adjacency_matrix rows>

<target_vertex_count>
<target_adjacency_matrix rows>
\end{verbatim}
Entries are integers; for simple graphs they are $0/1$.
For undirected graphs the adjacency matrix should be symmetric and the diagonal typically contains zeros.

\paragraph{Basic usage.}
\begin{verbatim}
./gempp [--time] [--ged] [--f2lp] [--minext-approx] [--up <v>] [--output <file>] <input_file.txt>
\end{verbatim}
Important flags:
\begin{itemize}
  \item \texttt{(no flag)}: compute the minimal extension (pattern into target) using the MCSM ILP formulation.
  \item \texttt{--ged} (or \texttt{-g}): solve full GED using the exact F2 integer formulation.
  \item \texttt{--f2lp} (or \texttt{--lp}): solve GED using the F2LP relaxation (continuous variables), yielding a lower bound on GED.
  \item \texttt{--minext-approx}: approximate minimal extension by running F2LP with a very high deletion cost.
  \item \texttt{--up <v>} (or \texttt{-u <v>}): pruning parameter in $(0,1]$ for the GED formulation (keeps only cheaper substitution candidates when $v<1$).
  \item \texttt{--output <file>} (or \texttt{-o <file>}): write a GEM++-style XML file describing the computed matching.
\end{itemize}

\paragraph{Parameter-based variable activation (\texttt{--up}).}
The GED/F2 formulation contains $|V_1||V_2|$ vertex variables $x_{i,k}$ and $|E_1||E_2|$ edge variables $y_{e,f}$.
To reduce solve time, we implement a heuristic candidate-pruning strategy controlled by \texttt{--up}:
\begin{itemize}
  \item for each pattern vertex (row) and each target vertex (column), only the cheapest fraction of $x_{i,k}$ candidates is kept active,
  \item after pruning $x$, any edge variable $y_{e,f}$ that is incompatible with the remaining active endpoint assignments is deactivated (fixed to $0$).
\end{itemize}
This typically speeds up solving substantially, but it is a heuristic restriction of the model: using \texttt{--up < 1} may prune away the true optimum for the integer (exact) formulation.
For fully exact results, use \texttt{--up 1.0}.

\paragraph{Output.}
In minimal-extension mode (default) the program prints:
\begin{verbatim}
GED: <value>
Is Subgraph: <yes|no>
Minimal Extension: <value>
Vertices to add: <count>
Edges to add: <count>
Unmatched vertices: <list or "none">
Unmatched edges: <list or "none">
\end{verbatim}
In GED mode the program reports unmatched vertices and edges on both sides (pattern and target).
With \texttt{--f2lp}, the printed GED value is a lower bound, since the optimization variables are continuous.

\paragraph{Testing.}
To verify correctness on the provided unit tests:
\begin{verbatim}
scripts\test.bat    (Windows)
./scripts/test.sh   (macOS/Linux)
\end{verbatim}

\section{Conclusions}

The work combines graph-theoretic concepts with an ILP-based implementation:

\begin{itemize}
  \item Graph size is defined as $\|G\| = |V(G)| + |E(G)|$, which aligns with
        the adjacency-matrix input size and is monotone under extensions.
  \item Graph edit distance $d_{\mathrm{GED}}$ is used as a metric on graphs
        and implemented via an ILP that counts vertex and edge insertions and
        deletions.
  \item Minimal extension is realised as a Minimum Cost Subgraph Matching
        problem, where the objective is the number of pattern vertices and
        edges that must be created in the target.
  \item The implementation is based on Integer Linear Programming (ILP) and the GLPK solver and supports both exact and relaxed formulations of these problems.
\end{itemize}

The experiments show two main regimes:

\begin{itemize}
  \item For graphs up to roughly 8--10 vertices (including dense complete
        graphs) the exact ILP solver is fast enough for interactive use.
  \item For dense graphs of size 12--15 the number of ILP variables and the
        solving time increase rapidly, reaching tens of seconds or minutes,
        which matches the theoretical hardness of subgraph isomorphism and
        GED.
\end{itemize}

\subsection*{Limitations}

The current solution has several clear limitations:

\begin{itemize}
  \item \textbf{Instance size.} The ILP formulation does not scale beyond
        small and medium graphs. For dense graphs with more than about
        15 vertices the solver becomes impractically slow.
  \item \textbf{Edit cost model.} All edit operations have unit cost. More
        refined cost models (e.g.\ different penalties for vertex vs.\ edge
        edits) are not exposed in the command-line interface.
  \item \textbf{Minimal extension parameter $k$.} The implementation focuses on
        $k=1$ (one copy of the pattern). Multiple required copies would need
        additional constraints in the ILP.
 
\end{itemize}



\begin{thebibliography}{9}

\bibitem{Bunke1997}
H.~Bunke.
\newblock On a relation between graph edit distance and maximum common
  subgraph.
\newblock {\em Pattern Recognition Letters}, 18(8):689--694, 1997.

\bibitem{RiesenBunke2009}
K.~Riesen and H.~Bunke.
\newblock Approximate graph edit distance computation by means of bipartite
  graph matching.
\newblock {\em Image and Vision Computing}, 27(7):950--959, 2009.

\bibitem{Solnon2015}
C.~Solnon, G.~Damiand, C.~de~la Higuera, and J.-C.~Janodet.
\newblock On the complexity of submap isomorphism and maximum common submap
  problems.
\newblock {\em Pattern Recognition}, 48(2):302--316, 2015.

\end{thebibliography}




\section*{References}
\begin{thebibliography}{9}

\bibitem{riesen2009}
P.~Riesen and H.~Bunke,
\emph{Approximate graph edit distance computation by means of bipartite graph matching},
Image and Vision Computing, 2009.

\bibitem{lerougeBLP}
J.~Lerouge, Z.~Abu-Aisheh, R.~Raveaux, P.~H{\'e}roux, and S.~Adam,
\emph{Graph edit distance: A new binary linear programming formulation},
Pattern Recognition Letters, 2015.

\bibitem{lerougeMCSM}
J.~Lerouge, M.~Hammami, P.~H{\'e}roux, and S.~Adam,
\emph{Minimum cost subgraph matching using a binary linear program},
Pattern Recognition Letters, 2016.

\end{thebibliography}

\end{document}

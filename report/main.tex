\documentclass[11pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel} % albo [polish], jeśli raport ma być po polsku
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{geometry}
\geometry{margin=2.5cm}

\title{Graph Distance and Minimal Extension\\
  \large Algorithms and Computability – Project Report}
\author{Borkowicz Dominik \and Volkau Kiryl \and Włodarczyk Wiktoria }
\date{\today}

\begin{document}

\maketitle

\section{Introduction}


\section{Preliminaries and Definitions}

We begin by specifying our graph model and by introducing the key concepts used throughout the report: graph size, a distance function on graphs, graph and subgraph isomorphism, and the minimal extension problem.

\subsection{Graph Model and Input Format}

In this project we work with finite, simple graphs.
A graph is a pair $G = (V,E)$, where $V$ is a finite set of vertices and $E \subseteq \{\{u,v\} \mid u,v \in V, u \neq v\}$ is a set of undirected edges.
We do not allow parallel edges or self-loops.
The methods considered in this report can be extended to other graph models (directed graphs, multigraphs).

We represent graphs by adjacency matrices.
Let $G = (V,E)$ with $V = \{1,\dots,n\}$.
The adjacency matrix $A \in \{0,1\}^{n \times n}$ of $G$ is defined by
\[
  A_{ij} =
  \begin{cases}
    1 & \text{if } \{i,j\} \in E,\\
    0 & \text{otherwise.}
  \end{cases}
\]
For undirected graphs the matrix is symmetric, $A_{ij} = A_{ji}$, and the diagonal entries are zero.



\subsection{Size of a Graph}

The notion of ``size'' of a graph is not uniquely fixed in the literature and may depend on the application.
For our purposes we define the size of a graph $G = (V,E)$ as
\[
  \mathrm{size}(G) = |V| + |E|.
\]

This definition has several desirable properties:
\begin{itemize}
  \item It takes into account both the number of objects (vertices) and the number of relationships (edges) in the graph.
  \item It is monotone with respect to adding vertices or edges: if $H$ is obtained from $G$ by adding vertices and/or edges, then $\mathrm{size}(H) \geq \mathrm{size}(G)$.
  \item It is linear in the natural parameters $|V|$ and $|E|$, which makes it convenient as a measure of input size in complexity analysis.
\end{itemize}
We use $\mathrm{size}(G)$ as a basic measure of the complexity of a single graph, and pairs such as $(\mathrm{size}(G), \mathrm{size}(H))$ as a measure of the size of an instance of our problems.

\subsection{Graph Edit Distance as a Metric}

Intuitively, the distance between two graphs should quantify how many modifications are needed to transform one graph into the other.
A standard notion capturing this idea is the \emph{graph edit distance} (GED) \cite{riesen2009,lerougeBLP}.
It is defined in terms of elementary edit operations on graphs.

We consider the following edit operations:
\begin{itemize}
  \item vertex insertion,
  \item vertex deletion,
  \item edge insertion,
  \item edge deletion.
\end{itemize}
Each operation has an associated non-negative cost.
In our setting we assume unit costs for all operations, but more general cost functions are possible.

An \emph{edit path} from a graph $G$ to a graph $H$ is a finite sequence of edit operations that transforms $G$ into $H$.
The cost of an edit path is the sum of the costs of its operations.
The graph edit distance between $G$ and $H$ is defined as
\[
  \mathrm{GED}(G,H) = \min \{ \mathrm{cost}(P) \mid P \text{ is an edit path from $G$ to $H$} \}.
\]

Under mild assumptions on the cost function (in particular, non-negativity and symmetry of insertion and deletion costs), GED satisfies the axioms of a metric on the space of graphs:
\begin{itemize}
  \item $\mathrm{GED}(G,H) \geq 0$ and $\mathrm{GED}(G,H) = 0$ if and only if $G$ and $H$ are isomorphic,
  \item $\mathrm{GED}(G,H) = \mathrm{GED}(H,G)$,
  \item $\mathrm{GED}(G,K) \leq \mathrm{GED}(G,H) + \mathrm{GED}(H,K)$ (triangle inequality).
\end{itemize}
We therefore use GED as a reasonable and well-established distance measure between graphs.

\subsection{Graph and Subgraph Isomorphism}

Two graphs $G = (V_G,E_G)$ and $H = (V_H,E_H)$ are \emph{isomorphic} if there exists a bijection
$f : V_G \to V_H$ such that
\[
  \{u,v\} \in E_G \quad \Longleftrightarrow \quad \{f(u), f(v)\} \in E_H
  \quad \text{for all } u,v \in V_G.
\]
Intuitively, isomorphic graphs have the same structure, differing only by the naming of vertices.

A graph $G$ is \emph{isomorphic to a subgraph} of $H$ if there exists an injective mapping
$f : V_G \to V_H$ such that
\[
  \{u,v\} \in E_G \quad \Longrightarrow \quad \{f(u), f(v)\} \in E_H
  \quad \text{for all } u,v \in V_G.
\]
In this case $H$ is said to \emph{contain} $G$ as a subgraph.
The subgraph isomorphism problem---deciding whether such an injective mapping exists---is a classical NP-complete problem.

There is a close connection between graph edit distance and (sub)graph isomorphism.
In particular, if the edit operations are restricted to vertex and edge relabellings and the cost of deletions and insertions is sufficiently large, then $\mathrm{GED}(G,H) = 0$ if and only if $G$ and $H$ are isomorphic.
Similarly, if only insertion operations are allowed, GED reduces to a measure of how far a graph is from containing another as a subgraph.

\subsection{Minimal Extension Problem}

We are now ready to formalize the main problem studied in this project.
Let $G$ and $H$ be two graphs.
We say that a graph $H'$ is an \emph{extension} of $H$ if $H$ is a subgraph of $H'$, that is, $V(H) \subseteq V(H')$ and $E(H) \subseteq E(H')$.

Given a pattern graph $G$, a base graph $H$, and an integer $k \geq 1$, the \emph{minimal extension problem} is defined as follows:
find an extension $H'$ of $H$ such that
\begin{itemize}
  \item $H'$ contains at least $k$ subgraphs that are isomorphic to $G$, and
  \item the number of vertices and edges added to $H$ to obtain $H'$ is minimal.
\end{itemize}
Equivalently, we seek an extension $H'$ minimizing the quantity
\[
  \Delta(H,H') = (|V(H')| - |V(H)|) + (|E(H')| - |E(H)|)
\]
subject to the constraint that $H'$ contains at least $k$ subgraphs isomorphic to $G$.

This problem can be viewed as a constrained variant of graph edit distance, where we allow only insertion operations and require the extended graph to contain a prescribed number of occurrences of a given pattern.

\section{Exact Algorithms}

In this section we describe exact algorithms for the problems introduced above.
We first discuss exact computation of the graph edit distance based on formulations proposed in the literature, and then we outline an exact approach to the minimal extension problem via exhaustive search of subgraph isomorphisms.
In both cases the algorithms have exponential worst-case complexity, which motivates the approximate methods presented in Section~\ref{sec:approx}.
 
\subsection{Exact Graph Edit Distance}
\label{subsec:exact-ged}

Exact computation of the graph edit distance is NP-hard in general and can be approached via binary linear programming (BLP).
In our implementation we follow the \emph{F2} formulation of Lerouge et al.\ \cite{lerougeBLP}, which is a reduced-size exact formulation compared to the straightforward model (\emph{F1}).

Let $G_1=(V_1,E_1)$ and $G_2=(V_2,E_2)$ be two graphs.
The formulation introduces two families of binary substitution variables:
\begin{itemize}
  \item $x_{i,k}\in\{0,1\}$ for $(i,k)\in V_1\times V_2$, where $x_{i,k}=1$ means that vertex $i$ is substituted (matched) with vertex $k$;
  \item $y_{e,f}\in\{0,1\}$ for $(e,f)\in E_1\times E_2$, where $y_{e,f}=1$ means that edge $e$ is substituted with edge $f$.
\end{itemize}
Deletion and insertion operations are handled implicitly: instead of explicit delete/insert variables, \emph{F2} uses a constant term corresponding to deleting and inserting all vertices and edges, and then subtracts the savings obtained by choosing substitutions.
Concretely, the objective has the form
\[
  \min_{x,y}\;\; C
  + \sum_{i\in V_1}\sum_{k\in V_2}\bigl(c_V(i\!\rightarrow\! k)-c_V(i\!\rightarrow\!\epsilon)-c_V(\epsilon\!\rightarrow\! k)\bigr)\,x_{i,k}
  + \sum_{e\in E_1}\sum_{f\in E_2}\bigl(c_E(e\!\rightarrow\! f)-c_E(e\!\rightarrow\!\epsilon)-c_E(\epsilon\!\rightarrow\! f)\bigr)\,y_{e,f},
\]
where $C = \sum_{i\in V_1}c_V(i\!\rightarrow\!\epsilon)+\sum_{k\in V_2}c_V(\epsilon\!\rightarrow\! k)+\sum_{e\in E_1}c_E(e\!\rightarrow\!\epsilon)+\sum_{f\in E_2}c_E(\epsilon\!\rightarrow\! f)$.
With unit insertion/deletion costs (our setting for unlabeled graphs), this simplifies to $C = |V_1|+|V_2|+|E_1|+|E_2|$.

The constraints enforce a one-to-one (partial) vertex assignment, a one-to-one edge assignment, and \emph{topological consistency} between the chosen vertex and edge substitutions.
The assignment constraints are:
\[
  \sum_{k\in V_2} x_{i,k} \le 1 \quad \forall i\in V_1,
  \qquad
  \sum_{i\in V_1} x_{i,k} \le 1 \quad \forall k\in V_2,
\]
and analogously for $y$ over $E_1$ and $E_2$.
The key reduction of \emph{F2} is to replace the quadratic number of edge-to-vertex compatibility constraints (one per pair of edges) by aggregated constraints indexed by vertices of $G_2$ (see \cite{lerougeBLP}).
For undirected graphs, this can be expressed as:
\[
  \sum_{f\in E_2:\; k\in f} y_{\{i,j\},f} \le x_{i,k}+x_{j,k}
  \qquad \forall \{i,j\}\in E_1,\; \forall k\in V_2.
\]

Solving this integer linear program yields an optimal edit path cost and therefore the exact value of $\mathrm{GED}(G_1,G_2)$.
The worst-case time complexity remains exponential (integer programming is NP-hard), but the reduced size of \emph{F2} makes it significantly more practical than the straightforward formulation for small and medium instances.

\subsection{Exact Subgraph Isomorphism and Minimal Extension}
\label{subsec:exact-extension}

We now turn to the minimal extension problem.
Recall that we are given a pattern graph $G$ and a base graph $H$, and we seek an extension $H'$ of $H$ that contains at least one subgraph isomorphic to $G$ while minimizing the number of added vertices and edges.

A conceptually simple exact algorithm is based on enumerating all injective mappings from the vertices of $G$ to the vertices of $H$ (and possibly to new vertices to be added) and computing, for each mapping, the minimal set of edges that must be added so that the image of $G$ under the mapping becomes a subgraph of the extended graph.

We first consider mappings into the existing vertices of $H$.
Let $V_G = \{1,\dots,n_G\}$ and $V_H = \{1,\dots,n_H\}$ with $n_G \leq n_H$.
An injective mapping $f : V_G \to V_H$ can be represented as an ordered $n_G$-tuple of distinct vertices of $H$.
For each such mapping we evaluate the \emph{deficit} of edges:
\[
  \mathrm{deficit}(f) = \left|\left\{ \{u,v\} \in E_G \;\middle|\; \{f(u), f(v)\} \notin E_H \right\}\right|.
\]
This quantity counts how many edges would need to be added to $H$ (between existing vertices) in order for the image of $G$ under $f$ to be realized as a subgraph of the extended graph.
The minimal deficit over all injective mappings into $V_H$ gives the minimal number of edge insertions required if we restrict ourselves to not adding new vertices.

If adding new vertices is allowed, the search space becomes even larger, since we may choose to map some vertices of $G$ to newly created vertices.
One possible exact strategy is then:
\begin{enumerate}
  \item For each integer $m \geq 0$ representing the number of new vertices to add, construct a hypothetical vertex set $V_H \cup V_{\mathrm{new}}$ with $|V_{\mathrm{new}}| = m$.
  \item Enumerate all injective mappings $f : V_G \to V_H \cup V_{\mathrm{new}}$.
  \item For each mapping compute the number of required edge insertions and count how many of them involve new vertices.
  \item Keep track of the mapping that minimizes the total number of inserted vertices and edges.
\end{enumerate}
The minimal total number of vertex and edge insertions over all considered values of $m$ gives the exact solution to the minimal extension problem.

The worst-case complexity of this exhaustive approach is clearly exponential.
Even if we restrict ourselves to mappings into the existing vertices of $H$, the number of injective mappings is
\[
  P(n_H, n_G) = \frac{n_H!}{(n_H - n_G)!},
\]
which grows superpolynomially in $n_H$ when $n_G$ is proportional to $n_H$.
For each mapping we must check all edges in $E_G$, which takes $O(|E_G|)$ time, or $O(n_G^2)$ in the worst case.
The overall worst-case time complexity is therefore
\[
  O\!\left(P(n_H, n_G) \cdot n_G^2\right),
\]
which is exponential in the size of the input graphs.

Because of this exponential behavior, exact algorithms for the minimal extension problem are practical only for very small graphs.
This observation motivates the design of approximate algorithms with polynomial-time complexity, as presented next.

\subsection{Minimal Extension via Minimum Cost Subgraph Matching (MCSM)}
\label{subsec:mcsm}

Our implementation computes the minimal extension using an integer linear programming (ILP) formulation of the \emph{Minimum Cost Subgraph Matching} (MCSM) problem \cite{lerougeMCSM}.
Conceptually, MCSM generalizes subgraph isomorphism by allowing a \emph{partial} injective mapping of the pattern into the target: some pattern vertices and edges may remain unmatched and incur a penalty.
With unit penalties for unmatched pattern elements, the MCSM objective directly corresponds to the ``minimal extension'' cost: the number of pattern vertices and edges that cannot be realized inside the target without adding new elements.

Let $G_1=(V_1,E_1)$ be the pattern and $G_2=(V_2,E_2)$ the target.
The formulation uses binary substitution variables
\(x_{i,k}\in\{0,1\}\) for $(i,k)\in V_1\times V_2$ and
\(y_{e,f}\in\{0,1\}\) for $(e,f)\in E_1\times E_2$,
where $x_{i,k}=1$ means that pattern vertex $i$ is matched to target vertex $k$ and $y_{e,f}=1$ means that pattern edge $e$ is matched to target edge $f$.
Deletions of pattern elements are handled implicitly: instead of explicit delete variables, the objective contains a constant term equal to the total ``creation cost'' of all pattern vertices and edges, and matching an element subtracts its creation cost and adds its substitution cost (which is $0$ in our unlabeled/unit-cost setting).
As a result, unmatched pattern vertices/edges contribute their full creation cost to the final objective.

The constraints enforce an injective partial mapping and topological consistency:
\begin{itemize}
  \item \textbf{Vertex injectivity.} Each pattern vertex is matched to at most one target vertex, and each target vertex is used by at most one pattern vertex:
  \[
    \sum_{k\in V_2} x_{i,k} \le 1 \quad \forall i\in V_1,
    \qquad
    \sum_{i\in V_1} x_{i,k} \le 1 \quad \forall k\in V_2.
  \]
  \item \textbf{Edge injectivity.} Each pattern edge is matched to at most one target edge (and symmetrically each target edge receives at most one pattern edge).
  \item \textbf{Edge--vertex consistency.} A pattern edge may be matched only to a target edge whose endpoints are compatible with the chosen endpoint matches.
  For undirected graphs, this can be enforced by aggregated constraints of the form
  \[
    \sum_{f\in E_2:\; k\in f} y_{e,f} \le x_{u,k}+x_{v,k}
    \quad \forall e=\{u,v\}\in E_1,\; \forall k\in V_2,
  \]
  which ensure that if $e$ is matched to an edge incident to $k$, then at least one endpoint of $e$ is matched to $k$.
\end{itemize}

This is exactly the approach implemented in our code in \texttt{src/formulation/mcsm.h}: the model allows \(\le 1\) (rather than equality) assignments for vertices and edges, and the objective counts the remaining unmatched pattern elements via their creation costs.
Optionally, we can also enforce an \emph{induced} subgraph match by adding constraints preventing the mapped target vertices from containing extra edges that are not matched by any pattern edge.


\section{Approximation Algorithms}
\label{sec:approx}

Exact algorithms for graph edit distance and the minimal extension problem are computationally expensive and do not scale to larger graphs.
In this section we describe approximation ideas that replace the exponential search space of exact formulations by tractable optimization problems.
In particular, for GED we use a linear programming relaxation (F2LP) of a binary linear formulation from the literature, which yields a polynomial-time computable lower bound.

\subsection{Approximate GED via LP Relaxation (F2LP)}
\label{subsec:approx-ged}

Instead of approximating GED via bipartite matching, we use the continuous relaxation of the binary linear programming formulation \emph{F2} proposed by Lerouge et al.\ \cite{lerougeBLP}.
In that work, \emph{F2LP} denotes the linear program obtained from \emph{F2} by relaxing all binary constraints to continuous bounds in $[0,1]$.
Solving \emph{F2LP} yields a polynomial-time computable \emph{lower bound} on the exact GED, and we use this value as our approximation.

Let $G_1=(V_1,E_1)$ and $G_2=(V_2,E_2)$ be two (simple, undirected) graphs.
We introduce decision variables:
\begin{itemize}
  \item $x_{i,k} \in [0,1]$ for each $(i,k)\in V_1\times V_2$, indicating to what extent vertex $i$ of $G_1$ is matched to vertex $k$ of $G_2$,
  \item $y_{e,f} \in [0,1]$ for each $(e,f)\in E_1\times E_2$, indicating to what extent edge $e$ of $G_1$ is matched to edge $f$ of $G_2$.
\end{itemize}

The \emph{F2} objective can be written as a constant corresponding to ``delete and insert everything'', plus correction terms for chosen substitutions:
\[
  \min_{x,y}\;\; C
  + \sum_{i\in V_1}\sum_{k\in V_2}\bigl(c_V(i\!\rightarrow\! k)-c_V(i\!\rightarrow\!\epsilon)-c_V(\epsilon\!\rightarrow\! k)\bigr)\,x_{i,k}
  + \sum_{e\in E_1}\sum_{f\in E_2}\bigl(c_E(e\!\rightarrow\! f)-c_E(e\!\rightarrow\!\epsilon)-c_E(\epsilon\!\rightarrow\! f)\bigr)\,y_{e,f}.
\]
In our experiments we use unit insertion/deletion costs and zero substitution costs for unlabeled graphs, so $C = |V_1|+|V_2|+|E_1|+|E_2|$, and matching vertices/edges decreases the objective accordingly.

The constraints enforce that $x$ behaves like a partial one-to-one assignment, and that $y$ is consistent with $x$:
\begin{align*}
  \sum_{k\in V_2} x_{i,k} &\le 1 && \forall i\in V_1,\\
  \sum_{i\in V_1} x_{i,k} &\le 1 && \forall k\in V_2,\\
  \sum_{f\in E_2} y_{e,f} &\le 1 && \forall e\in E_1,\\
  \sum_{e\in E_1} y_{e,f} &\le 1 && \forall f\in E_2,\\
  \sum_{f\in E_2:\; k\in f} y_{\{i,j\},f} &\le x_{i,k} + x_{j,k} && \forall \{i,j\}\in E_1,\;\forall k\in V_2,\\
  0 \le x_{i,k} \le 1,\;\; 0 \le y_{e,f} \le 1. &&
\end{align*}

The last family of constraints is the (undirected) \emph{edge consistency} condition: an edge $\{i,j\}\in E_1$ may be matched to an edge incident to $k\in V_2$ only if (at least) one of its endpoints is matched to $k$.
Replacing integrality ($\{0,1\}$) by bounds ($[0,1]$) gives the LP relaxation \emph{F2LP}, which can be solved efficiently by standard LP solvers.
The optimum value of \emph{F2LP} is a lower bound on the exact GED \cite{lerougeBLP}, and we report it as our polynomial-time approximation.

\subsection{Approximate Minimal Extension}
\label{subsec:approx-extension}

We also implemented a lightweight approximation of the minimal extension problem based on the same linear relaxation used for approximate GED, but with \emph{asymmetric} edit costs.
The key idea is to discourage deletions of pattern elements so that the optimization behaves like an ``embed the pattern into the target'' procedure.

Given a pattern graph $G=(V_G,E_G)$ and a base graph $H=(V_H,E_H)$, we solve the \emph{F2LP} relaxation (Section~\ref{subsec:approx-ged}) with costs chosen as:
\begin{itemize}
  \item insertion costs $c(\epsilon\rightarrow v)=1$ and $c(\epsilon\rightarrow e)=1$,
  \item deletion costs $c(v\rightarrow \epsilon)=M$ and $c(e\rightarrow \epsilon)=M$, where $M\gg 1$ is a very large constant.
\end{itemize}
Intuitively, with $M$ large the solver is strongly incentivized to \emph{avoid deleting} vertices and edges of $G$ and instead to explain discrepancies through the (cheaper) insertion of missing elements.
In our implementation we use $M=10^6$.

After solving the LP, we extract a discrete matching by treating variables with value at least $0.5$ as active.
Let $U_V$ be the set of pattern vertices not matched by any active $x_{i,k}$, and let $U_E$ be the set of pattern edges not matched by any active $y_{e,f}$.
We interpret these unmatched pattern elements as elements that would need to be \emph{added to $H$} so that an embedding of $G$ becomes possible, and we define the approximate extension size by
\[
  \widehat{\Delta}_{\mathrm{F2LP}}(H,H') = |U_V| + |U_E|.
\]
This procedure is heuristic: because we solve the relaxed program (continuous variables), the extracted matching may be fractional before thresholding, and the resulting count is only an approximation.

The overall running time is polynomial: solving the linear program dominates, and the post-processing step (counting unmatched pattern vertices and edges) is linear in $|V_G|+|E_G|$ once the active variables are identified.

\subsection{Discussion of Approximation Quality}
\label{subsec:approx-discussion}

The matching-based approach described above does not guarantee that the obtained value $\widehat{\mathrm{GED}}(G,H)$ equals the true graph edit distance, nor that the estimated extension cost $\widehat{\Delta}(H,H')$ is minimal.
The main source of approximation error is the locality of the cost matrix construction: the matching cost of two vertices is computed based on local information (labels, degrees, neighborhoods), whereas the global structure of the graphs may require more complex transformations.

Nevertheless, several practical advantages justify this approach:
\begin{itemize}
  \item The algorithm has polynomial worst-case complexity and can therefore handle graphs of significantly larger size than exact methods.
  \item The assignment-based correspondence typically captures a reasonable structural alignment between the graphs, especially when their local neighborhoods are informative.
  \item On small instances where the exact GED or exact minimal extension can be computed, empirical studies often show that the approximation is close to the true value \cite{riesen2009,lerougeBLP}.
\end{itemize}

In our experimental evaluation (Section~\ref{sec:experiments}) we compare the runtime and, where possible, the accuracy of the approximate methods against exact reference values.
The results confirm the expected trade-off: exact algorithms yield ground-truth distances but become infeasible beyond small graph sizes, while the approximate algorithms scale to larger inputs at the price of a moderate approximation error.

\section{Experimental Evaluation}
\label{sec:experiments}

\subsection{Input Size Measures}
For an instance consisting of a pattern graph $G_1=(V_1,E_1)$ and a target graph $G_2=(V_2,E_2)$, we report:
\[
  |V_1|,\; |E_1|,\; |V_2|,\; |E_2|,
\]
as well as the graph size $\mathrm{size}(G)=|V|+|E|$ introduced earlier.
For the optimization-based methods, a useful proxy for difficulty is the number of decision variables, which is on the order of $|V_1||V_2|$ (vertex matches) plus $|E_1||E_2|$ (edge matches), with additional constraints enforcing injectivity and edge consistency.

\subsection{Experimental Setup}
All experiments were run using the provided command-line tool \texttt{gempp} built with the standard CMake build scripts.
We measure wall-clock runtime using the program's built-in \texttt{--time} flag, which reports elapsed time in milliseconds for a single run (including parsing, model construction, solving, and solution extraction).

\subsection{Synthetic Instances}
To make the evaluation reproducible, we generated a small set of synthetic instances and stored them in \texttt{report/experiments\_inputs/}.
Table~\ref{tab:exp-instances} lists their sizes.

\begin{table}[h]
\centering
\begin{tabular}{lrrrr}
\toprule
Instance & $|V_1|$ & $|E_1|$ & $|V_2|$ & $|E_2|$ \\
\midrule
\texttt{exp1\_k3\_in\_p4} & 3 & 3  & 4 & 3  \\
\texttt{exp2\_p5\_in\_p4} & 5 & 4  & 4 & 3  \\
\texttt{exp3\_k4\_in\_p6} & 4 & 6  & 6 & 5  \\
\texttt{exp4\_c5\_in\_k5} & 5 & 5  & 5 & 10 \\
\texttt{exp5\_k6\_in\_k7} & 6 & 15 & 7 & 21 \\
\bottomrule
\end{tabular}
\caption{Synthetic inputs used in the experimental evaluation.}
\label{tab:exp-instances}
\end{table}

\subsection{Runtime and Result Comparison}
We evaluated four modes:
(i) minimal extension via MCSM (default),
(ii) exact GED via the integer F2 formulation (\texttt{--ged}),
(iii) the LP relaxation F2LP (\texttt{--f2lp}) yielding a lower bound on GED,
and (iv) the heuristic \texttt{--minext-approx} mode (F2LP with a very high deletion cost).
Table~\ref{tab:exp-results} summarizes the observed values and runtimes.

\begin{table}[h]
\centering
\begin{tabular}{lrrrrrrrr}
\toprule
 & \multicolumn{2}{c}{MinExt (MCSM)} & \multicolumn{2}{c}{GED (F2)} & \multicolumn{2}{c}{F2LP (LB)} & \multicolumn{2}{c}{MinExt-approx} \\
\cmidrule(lr){2-3}\cmidrule(lr){4-5}\cmidrule(lr){6-7}\cmidrule(lr){8-9}
Instance & value & ms & value & ms & value & ms & count & ms \\
\midrule
\texttt{exp1\_k3\_in\_p4} & 1 & 8  & 3 & 1  & 1.0 & 0 & 0  & 0 \\
\texttt{exp2\_p5\_in\_p4} & 2 & 1  & 2 & 1  & 2.0 & 0 & 4  & 0 \\
\texttt{exp3\_k4\_in\_p6} & 3 & 30 & 7 & 30 & 3.0 & 1 & 4  & 1 \\
\texttt{exp4\_c5\_in\_k5} & 0 & 1  & 5 & 1  & 5.0 & 1 & 0  & 0 \\
\texttt{exp5\_k6\_in\_k7} & 0 & 46 & 7 & 46 & 7.0 & 6 & 18 & 6 \\
\bottomrule
\end{tabular}
\caption{Measured runtimes (ms) and objective values for different modes. For \texttt{--f2lp}, the value is a lower bound on GED. For \texttt{--minext-approx}, ``count'' is the reported number of unmatched pattern vertices and edges after thresholding LP variables at $0.5$.}
\label{tab:exp-results}
\end{table}

\subsection{Discussion}
The results highlight several important points:
\begin{itemize}
  \item \textbf{Minimal extension vs.\ GED.} Even when $G_1$ is a subgraph of $G_2$ (extension cost $0$), the full GED can be positive because GED is symmetric and also accounts for deleting extra vertices/edges present in $G_2$ (e.g.\ \texttt{exp4\_c5\_in\_k5}).
  \item \textbf{Speed of F2LP.} The LP relaxation is consistently faster than solving the integer program on denser instances (e.g.\ \texttt{exp5\_k6\_in\_k7}: $6$ms vs.\ $46$ms), while providing a certified lower bound on GED.
  \item \textbf{Quality of the lower bound.} The bound can be tight on some instances (e.g.\ \texttt{exp4}, \texttt{exp5}) but loose on others (\texttt{exp1}, \texttt{exp3}), reflecting the relaxation gap.
  \item \textbf{Limitations of \texttt{--minext-approx}.} The high-deletion-penalty F2LP heuristic does not reliably recover the true minimal extension from the pattern-side unmatched count (e.g.\ \texttt{exp1} and \texttt{exp5}).
  This is expected because (a) the underlying optimization is a relaxation with fractional solutions, and (b) extracting a discrete matching by thresholding is itself heuristic.
\end{itemize}

\section{Implementation and Usage}
This section provides a short technical description of the implemented program and practical instructions for compiling and running it, as required by the laboratory task specification \cite{lerougeMCSM}.

\subsection{Software Architecture}
The project is a small C++17 command-line application that formulates the considered problems as linear/integer linear programs and solves them using GLPK.
The code is organized into a few focused modules:
\begin{itemize}
  \item \textbf{Input parsing} (\texttt{src/model/adjacency\_parser.h}): reads two graphs from a single text file containing adjacency matrices.
  \item \textbf{Graph model} (\texttt{src/model/graph.h}, \texttt{src/model/problem.h}): in-memory representation of the pattern and target graphs and the problem type (minimal extension vs.\ GED).
  \item \textbf{Formulations} (\texttt{src/formulation/}):
  \begin{itemize}
    \item \textbf{Minimal extension (default)}: a Minimum Cost Subgraph Matching (MCSM) ILP (\texttt{mcsm.h}), where the objective counts unmatched pattern vertices and edges.
    \item \textbf{Exact GED}: the F2 integer formulation implemented in \texttt{linear\_ged.h} (binary variables).
    \item \textbf{Approximate GED / bounds}: the F2LP relaxation in \texttt{linear\_ged.h} (continuous variables in $[0,1]$), enabled via a command-line flag.
    \item \textbf{Approximate minimal extension (heuristic)}: F2LP with a very high deletion penalty to discourage deleting pattern elements (Section~\ref{subsec:approx-extension}).
  \end{itemize}
  \item \textbf{Solver backend} (\texttt{src/solver/glpk\_solver.h}): translates the internal LP/ILP representation to GLPK and extracts a solution.
  \item \textbf{CLI entry point} (\texttt{src/main.cpp}): parses command-line flags, runs the selected mode, prints results, and optionally writes a GEM++-style XML solution file.
\end{itemize}
GLPK (GNU Linear Programming Kit) is an open-source optimization library that can solve \emph{linear programs} (LP) and \emph{mixed-integer linear programs} (MILP) using implementations of simplex/interior-point methods and branch-and-bound/branch-and-cut techniques.
We use it as the underlying solver for both our LP relaxation (F2LP) and our integer formulations (MCSM, F2).
For reproducibility, the repository also contains scripts for building, testing, and benchmarking (\texttt{scripts/}) and a small unit test suite (\texttt{tests/}).

\subsection{Running the Program}

\paragraph{Building.}
On Windows (laboratory environment), compile using:
\begin{verbatim}
scripts\build.bat
\end{verbatim}
On macOS/Linux:
\begin{verbatim}
./scripts/build.sh
\end{verbatim}
Alternatively, the build can be performed manually with CMake (e.g.\ \texttt{mkdir build \&\& cd build; cmake ..; make}).
The resulting executable is \texttt{gempp.exe} on Windows and \texttt{gempp} on macOS/Linux.

\paragraph{Input format.}
The program reads a \emph{single} text file containing two graphs (pattern first, target second):
\begin{verbatim}
<pattern_vertex_count>
<pattern_adjacency_matrix rows>

<target_vertex_count>
<target_adjacency_matrix rows>
\end{verbatim}
Entries are integers; for simple graphs they are $0/1$.
For undirected graphs the adjacency matrix should be symmetric and the diagonal typically contains zeros.

\paragraph{Basic usage.}
\begin{verbatim}
./gempp [--time] [--ged] [--f2lp] [--minext-approx] [--up <v>] [--output <file>] <input_file.txt>
\end{verbatim}
Important flags:
\begin{itemize}
  \item \texttt{(no flag)}: compute the minimal extension (pattern into target) using the MCSM ILP formulation.
  \item \texttt{--ged} (or \texttt{-g}): solve full GED using the exact F2 integer formulation.
  \item \texttt{--f2lp} (or \texttt{--lp}): solve GED using the F2LP relaxation (continuous variables), yielding a lower bound on GED.
  \item \texttt{--minext-approx}: approximate minimal extension by running F2LP with a very high deletion cost.
  \item \texttt{--up <v>} (or \texttt{-u <v>}): pruning parameter in $(0,1]$ for the GED formulation (keeps only cheaper substitution candidates when $v<1$).
  \item \texttt{--output <file>} (or \texttt{-o <file>}): write a GEM++-style XML file describing the computed matching.
\end{itemize}

\paragraph{Parameter-based variable activation (\texttt{--up}).}
The GED/F2 formulation contains $|V_1||V_2|$ vertex variables $x_{i,k}$ and $|E_1||E_2|$ edge variables $y_{e,f}$.
To reduce solve time, we implement a heuristic candidate-pruning strategy controlled by \texttt{--up}:
\begin{itemize}
  \item for each pattern vertex (row) and each target vertex (column), only the cheapest fraction of $x_{i,k}$ candidates is kept active,
  \item after pruning $x$, any edge variable $y_{e,f}$ that is incompatible with the remaining active endpoint assignments is deactivated (fixed to $0$).
\end{itemize}
This typically speeds up solving substantially, but it is a heuristic restriction of the model: using \texttt{--up < 1} may prune away the true optimum for the integer (exact) formulation.
For fully exact results, use \texttt{--up 1.0}.

\paragraph{Output.}
In minimal-extension mode (default) the program prints:
\begin{verbatim}
GED: <value>
Is Subgraph: <yes|no>
Minimal Extension: <value>
Vertices to add: <count>
Edges to add: <count>
Unmatched vertices: <list or "none">
Unmatched edges: <list or "none">
\end{verbatim}
In GED mode the program reports unmatched vertices and edges on both sides (pattern and target).
With \texttt{--f2lp}, the printed GED value is a lower bound, since the optimization variables are continuous.

\paragraph{Testing.}
To verify correctness on the provided unit tests:
\begin{verbatim}
scripts\test.bat    (Windows)
./scripts/test.sh   (macOS/Linux)
\end{verbatim}

\section{Conclusions}
% Ta sekcja odpowiada punktowi (e) – wnioski końcowe.
% - Podsumowanie osiągnięć:
%   * zdefiniowane pojęcia, zaproponowane algorytmy, implementacja,
%   * najważniejsze obserwacje z eksperymentów.
% - Ograniczenia obecnego podejścia.
% - Propozycje przyszłych prac (lepsze heurystyki, rozszerzenie na multigrafy itd.).

\section*{References}
\begin{thebibliography}{9}

\bibitem{riesen2009}
P.~Riesen and H.~Bunke,
\emph{Approximate graph edit distance computation by means of bipartite graph matching},
Image and Vision Computing, 2009.

\bibitem{lerougeBLP}
J.~Lerouge, Z.~Abu-Aisheh, R.~Raveaux, P.~H{\'e}roux, and S.~Adam,
\emph{Graph edit distance: A new binary linear programming formulation},
Pattern Recognition Letters, 2015.

\bibitem{lerougeMCSM}
J.~Lerouge, M.~Hammami, P.~H{\'e}roux, and S.~Adam,
\emph{Minimum cost subgraph matching using a binary linear program},
Pattern Recognition Letters, 2016.

\end{thebibliography}

\end{document}
